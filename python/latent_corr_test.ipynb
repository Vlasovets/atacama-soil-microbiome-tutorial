{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from latentcor import get_tps, latentcor\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall latentcor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    \"\"\"\n",
    "    transforms to the simplex\n",
    "    X should be of a pd.DataFrame of form (p,N)\n",
    "    \"\"\"\n",
    "    return X / X.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geometric_mean(x, positive=False):\n",
    "    \"\"\"\n",
    "    calculates the geometric mean of a vector\n",
    "    \"\"\"\n",
    "    assert not np.all(x == 0)\n",
    "\n",
    "    if positive:\n",
    "        x = x[x > 0]\n",
    "    a = np.log(x)\n",
    "    g = np.exp(a.sum() / len(a))\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transform(X, transformation=str, eps=0.1):\n",
    "    \"\"\"\n",
    "    log transform, scaled with geometric mean\n",
    "    X should be a pd.DataFrame of form (p,N)\n",
    "    \"\"\"\n",
    "    if transformation == \"clr\":\n",
    "        assert not np.any(X.values == 0), \"Add pseudo count before using clr\"\n",
    "        g = X.apply(geometric_mean)\n",
    "        Z = np.log(X / g)\n",
    "    elif transformation == \"mclr\":\n",
    "        g = X.apply(geometric_mean, positive=True)\n",
    "        X_pos = X[X > 0]\n",
    "        Z = np.log(X_pos / g)\n",
    "        Z = Z + abs(np.nanmin(Z.values)) + eps\n",
    "        Z = Z.fillna(0)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_features(X: pd.DataFrame, transformation: str = \"clr\", pseudo_count: int = 1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Project compositional data to Euclidean space.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pseudo_count: int, optional\n",
    "        Add pseudo count, only necessary for transformation = \"clr\".\n",
    "    table: biom.Table\n",
    "        A table with count microbiome data.\n",
    "    transformation: str\n",
    "        If 'clr' the data is transformed with center log-ratio method by Aitchison (1982).\n",
    "        If 'mclr' the data is transformed with modified center log-ratio method by Yoon et al. (2019).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X: pd.Dataframe\n",
    "        Count data projected to Euclidean space.\n",
    "\n",
    "    \"\"\"\n",
    "    columns = X.columns\n",
    "\n",
    "    if transformation == \"clr\":\n",
    "        X = zero_imputation(X, pseudo_count=pseudo_count)\n",
    "        X = normalize(X)\n",
    "        X = log_transform(X, transformation=transformation)\n",
    "\n",
    "        return pd.DataFrame(X, columns=columns)\n",
    "\n",
    "    elif transformation == \"mclr\":\n",
    "        X = normalize(X)\n",
    "        X = log_transform(X, transformation=transformation)\n",
    "\n",
    "        return pd.DataFrame(X, columns=columns)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Unknown transformation name, use clr and not %r\" % transformation\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_heatmap(corr_df, title=None, show_plot=False):\n",
    "    \"\"\"\n",
    "    Visualize correlation matrix with heatmap.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    corr_df: pd.Series\n",
    "        Pandas dataframe representing correlation matrix (symmetric).\n",
    "    title: str, optional\n",
    "        Title of the plot.\n",
    "    show_plot: bool, optional\n",
    "        Show the plot as an output.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fig: plotly.go object\n",
    "        Heatmap figure.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    heat = go.Heatmap(\n",
    "        z = corr_df,\n",
    "        x = corr_df.columns.values,\n",
    "        y = corr_df.columns.values,\n",
    "        zmin = - 1, # Sets the lower bound of the color domain\n",
    "        zmax = 1,\n",
    "        xgap = 1, # Sets the horizontal gap (in pixels) between bricks\n",
    "        ygap = 1,\n",
    "        colorscale = 'RdBu_r'\n",
    "    )\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title_text=title, \n",
    "        title_x=0.5, \n",
    "        width=2400, \n",
    "        height=2400,\n",
    "        xaxis_showgrid=False,\n",
    "        yaxis_showgrid=False,\n",
    "        yaxis_autorange='reversed'\n",
    "    )\n",
    "\n",
    "    fig=go.Figure(data=[heat], layout=layout)\n",
    "    if show_plot:\n",
    "        fig.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atacama soil microbiome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import count data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original data has been published by [Christian L Lauber](https://pubmed.ncbi.nlm.nih.gov/19502440/).\n",
    "\n",
    "We have preprocessed the data with [Qiime2](https://github.com/Vlasovets/q2-gglasso/blob/master/example/atacama/atacama_example.ipynb) which resulted in having 53 samples and 130 ASVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acm_soil_counts = pd.read_csv('~/q2-gglasso/data/atacama-table_org/composition_feature-table.tsv', sep='\\t', index_col = 0)\n",
    "acm_soil_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Microbial count data is zero-inflated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acm_soil_counts.iloc[:, 0].plot.hist(bins=24, alpha=1).get_figure().savefig('org_count.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also compositional and we apply mclr-transformation to avoid unit-sum constraint in the sample vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acm = transform_features(acm_soil_counts, transformation=\"mclr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acm.iloc[:, 0].plot.hist(bins=24, alpha=1).get_figure().savefig('mclr_count.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 15 numeric covariates associated with microbial count data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covariates\n",
    "meta = pd.read_csv('~/GGLasso/data/soil/processed/acm_meta.tsv', sep='\\t', index_col = 0)\n",
    "\n",
    "meta = meta.loc[:, meta.iloc[0, :] != 'categorical'] # take numeric features\n",
    "meta = meta.apply(pd.to_numeric, errors='coerce') # make sure every feature has a numeric type\n",
    "meta = meta.dropna(how='all') # drop entire empty columns if any\n",
    "\n",
    "# meta = meta.iloc[1:]\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(5,3,figsize=(15, 20))\n",
    "meta.hist(ax=axis)\n",
    "# fig.savefig('meta_hist.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The covariates have different scale and we need to standartise with $mu=0$ and $\\sigma=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(meta)\n",
    "scaled = scaler.transform(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_scaled = pd.DataFrame(scaled, index=meta.index, columns=meta.columns)\n",
    "\n",
    "fig, axis = plt.subplots(5,3,figsize=(15, 20))\n",
    "meta_scaled.hist(ax=axis)\n",
    "\n",
    "# fig.savefig('meta_hist_scaled.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge counts and covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we merge counts and covariates by sample ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join by sample id\n",
    "acm_T = acm.T \n",
    "\n",
    "df = acm_T.join(meta_scaled) # left join\n",
    "\n",
    "df.isnull().sum().any() # check missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are missing values which will prevent us calculating latent correlation, so impute them with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)\n",
    "\n",
    "df.isnull().sum().any() # check missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to drop features with no variance if any to be able to calculate the correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop covariates with zero variance\n",
    "for var in df.columns:\n",
    "    if df[var].var() == 0:\n",
    "        print(\"'{0}' covariate has been dropped\".format(var))\n",
    "        del df[var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N, p\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We rename ASVs features indices with shorter names for visualization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename long feature IDs with concise names\n",
    "id_dict = dict()\n",
    "\n",
    "i = 1\n",
    "for col in vis_df.columns:\n",
    "    # length of ASVs identifier\n",
    "    if len(col) == 32:\n",
    "        asv_name = \"ASV_{0}\".format(i)\n",
    "        id_dict[asv_name] = col\n",
    "        vis_df.rename(columns={col: asv_name}, inplace=True)\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "vis_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent correlation with latentcorr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We automatically extract mixed types from the data using get_tps() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, p = df.shape\n",
    "\n",
    "clean_types = get_tps(vis_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The count table is supposed to be truncated type, but since we have few samples and the data is strongly zero-inflated some of the features considered to be binary or ternary. Covariates as expected mostly have continious type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### N, p input\n",
    "org_lat_cor = latentcor(vis_df, tps=clean_types, method='original', use_nearPD=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_org = org_lat_cor['R']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appoximate method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approx_pdTRUE = latentcor(vis_df, tps=clean_types, method='approx', use_nearPD=True, nu=0.001, tol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_pdTRUE = approx_pdTRUE['R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approx_pdFALSE = latentcor(vis_df, tps=clean_types, method='approx', use_nearPD=False, nu=0.001, tol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_pdFALSE = approx_pdFALSE[\"R\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The latent correlation matrices are very unlike to Kendall correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kendall = vis_df.corr(method='kendall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kendall_fig = corr_heatmap(kendall,title=\"Kendall correlation\", show_plot=True)\n",
    "# kendall_fig.write_image(\"kendall.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_org_fig = corr_heatmap(R_org, title=\"Orgiginal latent correlation correlation\", show_plot=True)\n",
    "# R_org_fig.write_image(\"orgiginal_latent_correlation.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_pdTRUE_fig = corr_heatmap(R_pdTRUE, title=\"Approximate latent correlation correlation with PD constraint\", show_plot=True)\n",
    "# R_pdTRUE_fig.write_image(\"approx_latent_correlation_PD.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_pdFALSE_fig = corr_heatmap(R_pdFALSE, title=\"Approximate latent correlation correlation WITHOUT PD constraint\", show_plot=True)\n",
    "# R_pdFALSE_fig.write_image(\"approx_latent_correlation_noPD.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difference between latent correlation and Kendall correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_ken_org = kendall - R_org\n",
    "\n",
    "diff_fig_org = corr_heatmap(diff_ken_org, title=\"Difference between Kendall and original latent correlation\", show_plot=True)\n",
    "# diff_fig_org.write_image(\"diff_ken_org.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_ken_apx_PD = kendall - R_pdTRUE\n",
    "\n",
    "diff_fig_apx_PD = corr_heatmap(diff_ken_apx_PD, title=\"Difference between Kendall and approximate latent correlation with PD constraint\", show_plot=True)\n",
    "# diff_fig_apx_PD.write_image(\"diff_ken_apx_PD.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_ken_apx_noPD = kendall - R_pdFALSE\n",
    "\n",
    "diff_fig_apx_noPD = corr_heatmap(diff_ken_apx_noPD, title=\"Difference between Kendall and approximate latent correlation WITHOUT PD constraint\", show_plot=True)\n",
    "# diff_fig_apx_noPD.write_image(\"diff_ken_apx_noPD.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of eigenvalue decomposotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_val_ken = np.linalg.eigvalsh(kendall)\n",
    "eig_val_R_org = np.linalg.eigvalsh(R_org)\n",
    "eig_val_R_pdTRUE = np.linalg.eigvalsh(R_pdTRUE)\n",
    "eig_val_R_pdFALSE = np.linalg.eigvalsh(R_pdFALSE)\n",
    "\n",
    "\n",
    "print(\"Kendall eigenvalue range:[{0}; {1}]\".format(eig_val_ken.min(), eig_val_ken.max()))\n",
    "print(\"Original eigenvalue range:[{0}; {1}]\".format(eig_val_R_org.min(), eig_val_R_org.max()))\n",
    "print(\"Approximate_PD eigenvalue range:[{0}; {1}]\".format(eig_val_R_pdTRUE.min(), eig_val_R_pdTRUE.max()))\n",
    "print(\"Approximate_noPD eigenvalue range:[{0}; {1}]\".format(eig_val_R_pdFALSE.min(), eig_val_R_pdFALSE.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = eig_val_ken\n",
    "x1 = eig_val_R_org\n",
    "x2 = eig_val_R_pdTRUE\n",
    "x3 = eig_val_R_pdFALSE\n",
    "\n",
    "eigen_fig = go.Figure()\n",
    "eigen_fig.add_trace(go.Histogram(x=x0, name='kendall', nbinsx=50))\n",
    "eigen_fig.add_trace(go.Histogram(x=x1, name='original', nbinsx=50))\n",
    "eigen_fig.add_trace(go.Histogram(x=x2, name='approx_PD', nbinsx=50))\n",
    "eigen_fig.add_trace(go.Histogram(x=x3, name='approx_noPD', nbinsx=50))\n",
    "\n",
    "eigen_fig.update_layout(barmode='overlay')\n",
    "eigen_fig.update_traces(opacity=0.55)\n",
    "\n",
    "eigen_fig.update_layout(\n",
    "    title=\"Comparison of eigenvalues produced by different correlation methods.\",\n",
    "    xaxis_title=\"Eigenvalues\",\n",
    "    yaxis_title=\"Count\",\n",
    "    legend_title=\"Legend Title\",\n",
    "    barmode='overlay',\n",
    "    width=800,\n",
    "    height=500\n",
    ")\n",
    "\n",
    "eigen_fig.show()\n",
    "# eigen_fig.write_image(\"eigen_fig.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
