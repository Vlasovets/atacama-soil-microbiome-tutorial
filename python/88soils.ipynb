{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import bisect\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "from itertools import chain\n",
    "from math import pi\n",
    "from sklearn import preprocessing\n",
    "from GGLasso.gglasso.problem import glasso_problem\n",
    "from utils import transform_features, scale_array_by_diagonal\n",
    "from utils import PCA\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.spatial import distance\n",
    "\n",
    "from networkx.utils import cuthill_mckee_ordering\n",
    "\n",
    "from bokeh.io import output_notebook, show, save\n",
    "from bokeh.models import Range1d, Circle, ColumnDataSource, MultiLine, HoverTool, LabelSet, PointDrawTool\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.plotting import from_networkx\n",
    "from bokeh.palettes import RdBu, Blues8\n",
    "from bokeh.models import HoverTool, Panel, Tabs, ColorBar, LinearColorMapper\n",
    "from bokeh.layouts import row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(X, L, inverse=True):\n",
    "    sig, V = np.linalg.eigh(L)\n",
    "\n",
    "    # sort eigenvalues in descending order\n",
    "    sig = sig[::-1]\n",
    "    V = V[:, ::-1]\n",
    "\n",
    "    ind = np.argwhere(sig > 1e-9)\n",
    "\n",
    "    if inverse:\n",
    "        loadings = V[:, ind] @ np.diag(np.sqrt(1 / sig[ind]))\n",
    "    else:\n",
    "        loadings = V[:, ind] @ np.diag(np.sqrt(sig[ind]))\n",
    "\n",
    "    # compute the projection\n",
    "    zu = X.values @ loadings\n",
    "\n",
    "    return zu, loadings, np.round(sig[ind].squeeze(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_heatmap(data: pd.DataFrame(), title: str = None, labels_dict: dict=None, labels_dict_reversed: dict=None,\n",
    "                  width: int = 1500, height: int = 1500, label_size: str = \"5pt\", not_low_rank: bool = True):\n",
    "    nlabels = len(labels_dict)\n",
    "    df = data.iloc[::-1] # rotate matrix 90 degrees\n",
    "    df = pd.DataFrame(df.stack(), columns=['covariance']).reset_index()\n",
    "    df.columns = [\"taxa_y\", \"taxa_x\", \"covariance\"]\n",
    "    if not_low_rank:\n",
    "        df = df.replace({\"taxa_x\": labels_dict, \"taxa_y\": labels_dict})\n",
    "\n",
    "    color_list, colors = _get_colors(df=df)\n",
    "    mapper = LinearColorMapper(palette=colors, low=-1, high=1)\n",
    "    color_bar = ColorBar(color_mapper=mapper, location=(0, 0))\n",
    "\n",
    "    bottom, top, left, right = _get_bounds(nlabels=nlabels)\n",
    "\n",
    "    source = ColumnDataSource(dict(top=top, bottom=bottom, left=left, right=right, color_list=color_list,\n",
    "                                   taxa_x=df['taxa_x'], taxa_y=df['taxa_y'], covariance=df['covariance']))\n",
    "\n",
    "    bokeh_tools = [\"save, zoom_in, zoom_out, wheel_zoom, box_zoom, crosshair, reset, hover\"]\n",
    "\n",
    "    p = figure(plot_width=width, plot_height=height, x_range=(0, nlabels), y_range=(0, nlabels),\n",
    "               title=title, title_location='above', x_axis_location=\"below\",\n",
    "               tools=bokeh_tools, toolbar_location='left')\n",
    "\n",
    "    p.quad(top=\"top\", bottom=\"bottom\", left=\"left\", right=\"right\", line_color='white', color=\"color_list\",\n",
    "           source=source)\n",
    "    p.xaxis.major_label_orientation = pi / 4\n",
    "    p.yaxis.major_label_orientation = \"horizontal\"\n",
    "    p.title.text_font_size = \"24pt\"\n",
    "    p.add_layout(color_bar, 'right')\n",
    "    p.toolbar.autohide = True\n",
    "\n",
    "    p.xaxis.ticker = list(range(0, nlabels))\n",
    "    p.yaxis.ticker = list(range(0, nlabels))\n",
    "    if not_low_rank:\n",
    "        p.xaxis.major_label_overrides = labels_dict\n",
    "        p.yaxis.major_label_overrides = labels_dict_reversed\n",
    "    p.xaxis.major_label_text_font_size = label_size\n",
    "    p.yaxis.major_label_text_font_size = label_size\n",
    "\n",
    "    hover = p.select(dict(type=HoverTool))\n",
    "    hover.tooltips = [\n",
    "        (\"taxa_x\", \"@taxa_x\"),\n",
    "        (\"taxa_y\", \"@taxa_y\"),\n",
    "        (\"covariance\", \"@covariance\"),\n",
    "    ]\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_network(G, title, width, height, node_size=None):\n",
    "    #Establish which categories will appear when hovering over each node\n",
    "    HOVER_TOOLTIPS = [(\"Character\", \"@index\")]\n",
    "    hover = HoverTool(tooltips=[('','@index')])\n",
    "    tools = [\"save, zoom_in, zoom_out, wheel_zoom, box_zoom, crosshair, reset, hover, pan\"]\n",
    "\n",
    "    #Create a plot â€” set dimensions, toolbar, and title\n",
    "    plot = figure(tooltips = HOVER_TOOLTIPS, plot_width=width, plot_height=height,\n",
    "                  tools=tools, active_scroll='wheel_zoom',\n",
    "                x_range=Range1d(-10.1, 10.1), \n",
    "                  y_range=Range1d(-10.1, 10.1), title=title)\n",
    "    \n",
    "    \n",
    "    \n",
    "    color_map = [\"#88CCEE\" if \"ASV\" in j else \"#DDCC77\" for j in G.nodes()] #green for bugs, and blue for covariates\n",
    "    nx.set_node_attributes(G, {j: {'color': color_map[i]} for i, j in enumerate(G.nodes())})\n",
    "\n",
    "    if node_size is not None:\n",
    "        n_degrees = {k: 15*v for k,v in G.degree()} \n",
    "        nx.set_node_attributes(G, n_degrees, 'node_size')\n",
    "        node_size = 'node_size'\n",
    "    else:\n",
    "        node_size = 40\n",
    "\n",
    "    network_graph = from_networkx(G, nx.spring_layout, scale=10, center=(0, 0))\n",
    "\n",
    "\n",
    "    #Set node size and color\n",
    "    network_graph.node_renderer.glyph = Circle(size=node_size,  fill_color=\"color\")\n",
    "    \n",
    "    #Set edge width and color\n",
    "    network_graph.edge_renderer.data_source.data[\"line_width\"] = [G.get_edge_data(a,b)['covariance']*2 for a, b in G.edges()]  ### amplify edges strengh\n",
    "    network_graph.edge_renderer.data_source.data[\"line_color\"] = [\"#117733\" if G.get_edge_data(a, b)['covariance'] >= 0 else \"#CC6677\" for a, b in G.edges()]\n",
    "    network_graph.edge_renderer.glyph.line_width = {'field': 'line_width'}\n",
    "    network_graph.edge_renderer.glyph.line_color = {'field': 'line_color'}\n",
    "\n",
    "    #Add network graph to the plot\n",
    "    plot.renderers.append(network_graph)\n",
    "    \n",
    "    x, y = zip(*network_graph.layout_provider.graph_layout.values())\n",
    "    node_labels = list(G.nodes)\n",
    "    source = ColumnDataSource({'x': x, 'y': y, 'asv': [node_labels[i] for i in range(len(x))]})\n",
    "    labels = LabelSet(x='x', y='y', text='asv', x_offset=30, y_offset=-15, source=source, render_mode='canvas', text_font_size='12pt')\n",
    "\n",
    "    plot.renderers.append(labels)    \n",
    "\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_corr(corr_array, inplace=False):\n",
    "    \"\"\"\n",
    "    Rearranges the correlation matrix, corr_array, so that groups of highly \n",
    "    correlated variables are next to eachother \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    corr_array : pandas.DataFrame or numpy.ndarray\n",
    "        a NxN correlation matrix \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame or numpy.ndarray\n",
    "        a NxN correlation matrix with the columns and rows rearranged\n",
    "    \"\"\"\n",
    "    pairwise_distances = sch.distance.pdist(corr_array)\n",
    "    linkage = sch.linkage(pairwise_distances, method='complete')\n",
    "    cluster_distance_threshold = pairwise_distances.max()/2\n",
    "    idx_to_cluster_array = sch.fcluster(linkage, cluster_distance_threshold, \n",
    "                                        criterion='distance')\n",
    "    idx = np.argsort(idx_to_cluster_array)\n",
    "    \n",
    "    if not inplace:\n",
    "        corr_array = corr_array.copy()\n",
    "    \n",
    "    if isinstance(corr_array, pd.DataFrame):\n",
    "        return corr_array.iloc[idx, :].T.iloc[idx, :]\n",
    "    return corr_array[idx, :][:, idx]\n",
    "\n",
    "\n",
    "# fig = px.imshow(-1*cluster_corr(precision_SGL), color_continuous_scale='RdBu_r', zmin=-1, zmax=1)\n",
    "# fig.update_layout(margin = dict(t=100,r=100,b=100,l=100), width = 1000, height = 1000,\n",
    "#                  title='Clustered Estimated inverse covariance: ASVs', title_x=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(corr_matrix: pd.DataFrame(), threshold: float):\n",
    "    #take the upper part only\n",
    "    upper = np.triu(np.ones(corr_matrix.shape)).astype(bool)\n",
    "    df = corr_matrix.where(upper)\n",
    "    df = pd.DataFrame(corr_matrix.stack(), columns=['covariance']).reset_index()\n",
    "    df.columns = [\"source\", \"target\", \"covariance\"]\n",
    "    \n",
    "    #remove diagonal entries\n",
    "    #df = df[df['covariance'] <= threshold]\n",
    "    df = df[abs(df['covariance']) >= threshold]\n",
    "    #remove diagonal entries\n",
    "    df = df[df['source'] != df['target']]\n",
    "    #remove zero entries\n",
    "    df = df[df['covariance'] != 0]\n",
    "    \n",
    "    #build graph\n",
    "    G = nx.from_pandas_edgelist(df, edge_attr=\"covariance\")\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_covariates(counts=pd.DataFrame(), metadata=pd.DataFrame(), L=np.ndarray, y=str):\n",
    "    proj, loadings, eigv = PCA(counts.dropna(), L, inverse=True)\n",
    "    r = np.linalg.matrix_rank(L)\n",
    "    eigv_sum = np.sum(eigv)\n",
    "    var_exp = [(value / eigv_sum) for value in sorted(eigv, reverse=True)]\n",
    "    \n",
    "    depth = pd.DataFrame(data=soil.sum(axis=0), columns=[\"sequencing depth\"])\n",
    "    metadata = depth.join(metadata)\n",
    "    \n",
    "    pc_columns = list('PC{0} ({1}%)'.format(i+1, str(100 * var_exp[i])[:4]) for i in range(0, r))\n",
    "    df_proj = pd.DataFrame(proj, columns=pc_columns, index=counts.index)\n",
    "    df = df_proj.join(metadata)\n",
    "    \n",
    "    varName1 = 'PC1 ({0}%)'.format(str(100 * var_exp[0])[:4])\n",
    "    varName2 = y\n",
    "    df['x'] = df[varName1]\n",
    "    df['y'] = df[varName2]\n",
    "\n",
    "    source = ColumnDataSource(df)\n",
    "\n",
    "    p0 = figure(tools='save, zoom_in, zoom_out, wheel_zoom, box_zoom, reset', plot_width=800, plot_height=800,\n",
    "                active_scroll=\"wheel_zoom\",\n",
    "                x_axis_label=varName1, y_axis_label=varName2,\n",
    "                tooltips=[(varName1, \"@\" + varName1),\n",
    "                          (varName2, \"@\" + varName2)\n",
    "                          ],\n",
    "                title=varName1 + \" vs \" + varName2)\n",
    "\n",
    "    exp_cmap = LinearColorMapper(palette=Blues8[::-1], low=min(df['sequencing depth'].values), high=max(df['sequencing depth'].values))\n",
    "    p0.circle('x', 'y', source=source, size=15, line_color=None, fill_color={\"field\": \"sequencing depth\", \"transform\": exp_cmap}, fill_alpha=0.3)\n",
    "\n",
    "    color_bar_plot = figure(title='sequencing depth', title_location=\"right\",\n",
    "                            height=500, width=150, toolbar_location=None, min_border=0,\n",
    "                            outline_line_color=None)\n",
    "\n",
    "    bar = ColorBar(color_mapper=exp_cmap, location=(1, 1))\n",
    "\n",
    "    color_bar_plot.add_layout(bar, 'right')\n",
    "    color_bar_plot.title.align = \"center\"\n",
    "    color_bar_plot.title.text_font_size = '12pt'\n",
    "\n",
    "    layout = row(p0, color_bar_plot)\n",
    "\n",
    "    return layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_labels(df):\n",
    "    i = 1\n",
    "    for col in df.columns:\n",
    "        # length of ASVs identifier\n",
    "        if col.isdigit():\n",
    "            asv_name = \"ASV_{0}\".format(i)\n",
    "            id_dict[asv_name] = col\n",
    "            df.rename(columns={col: asv_name}, inplace=True)\n",
    "\n",
    "            i += 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_bounds(nlabels: int):\n",
    "    bottom = list(chain.from_iterable([[ii] * nlabels for ii in range(nlabels)]))\n",
    "    top = list(chain.from_iterable([[ii + 1] * nlabels for ii in range(nlabels)]))\n",
    "    left = list(chain.from_iterable([list(range(nlabels)) for ii in range(nlabels)]))\n",
    "    right = list(chain.from_iterable([list(range(1, nlabels + 1)) for ii in range(nlabels)]))\n",
    "\n",
    "    return bottom, top, left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_colors(df: pd.DataFrame(), n_colors: int = 9):\n",
    "    colors = list(RdBu[n_colors])\n",
    "    ccorr = np.arange(-1, 1, 1 / (len(colors) / 2))\n",
    "    color_list = []\n",
    "    for value in df.covariance.values:\n",
    "        ind = bisect.bisect_left(ccorr, value) # smart array insertion\n",
    "        if ind == 0: # avoid ind == -1 on the next step\n",
    "            ind = ind + 1\n",
    "        color_list.append(colors[ind-1])\n",
    "    return color_list, colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_dict(df):\n",
    "    n_labels = len(df.columns)\n",
    "    labels_dict = dict(zip(range(n_labels), df.columns))\n",
    "    labels_dict_reversed = dict(zip(range(n_labels),list(labels_dict.values())[::-1]))\n",
    "    \n",
    "    return labels_dict, labels_dict_reversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scater_plot(x, y, width=800, height=600, size=3):\n",
    "    bokeh_tools = [\"save, zoom_in, zoom_out, wheel_zoom, box_zoom, crosshair, reset, hover\"]\n",
    "    p = figure(plot_width=width, plot_height=height, tools=bokeh_tools, toolbar_location='left')\n",
    "\n",
    "    source = ColumnDataSource({'x': x, 'y': y})\n",
    "\n",
    "    p.circle(\"x\", \"y\", size=size, source=source, line_color=None)\n",
    "\n",
    "    p.xaxis.axis_label = x.name\n",
    "    p.yaxis.axis_label = y.name\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soil = pd.read_csv('~/GGlasso/data/soil/processed/soil_116.csv', sep=',', index_col = 0).T\n",
    "print(soil.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr = transform_features(soil, transformation=\"mclr\")\n",
    "clr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = soil.sum(axis=0)\n",
    "\n",
    "meta = pd.read_table('~/GGlasso//data/soil/original/88soils_modified_metadata.txt', index_col=0)\n",
    "\n",
    "selected_covariates = ['tot_org_carb', 'elevation', 'carb_nitro_ratio', 'annual_season_temp', 'ph']\n",
    "\n",
    "meta = meta[selected_covariates].reindex(soil.columns)\n",
    "\n",
    "if (meta == 0).any().any():\n",
    "    print(\"The DataFrame contains at least one zero.\")\n",
    "else:\n",
    "    print(\"The DataFrame does not contain any zeros.\")\n",
    "\n",
    "\n",
    "\n",
    "# #scale data\n",
    "scaler = preprocessing.StandardScaler().fit(meta)\n",
    "meta_scaled = scaler.transform(meta)\n",
    "meta_scaled = pd.DataFrame(meta_scaled, index=meta.index, columns=meta.columns)\n",
    "\n",
    "# # transpose count data\n",
    "clr_T = clr.T\n",
    "# join by sample id\n",
    "df = clr_T.join(meta_scaled)\n",
    "\n",
    "# # Rename long feature IDs with concise names\n",
    "vis_df = df.copy()\n",
    "id_dict = dict()\n",
    "vis_df = add_labels(vis_df)\n",
    "\n",
    "# #calculate covariance\n",
    "n_cov = meta_scaled.shape[1]\n",
    "asv = df.iloc[:, :-n_cov]\n",
    "S = np.cov(asv.T.values, bias=True)\n",
    "\n",
    "# # correlation between ASVs ONLY\n",
    "corr = scale_array_by_diagonal(S)\n",
    "\n",
    "# #add labels\n",
    "asv_names = vis_df.iloc[:, :-n_cov].columns\n",
    "vis_S = pd.DataFrame(corr, columns=asv_names, index=asv_names)\n",
    "\n",
    "# # # correlation between ASVs and covariates\n",
    "S_meta = np.cov(df.T.values, bias=True)\n",
    "corr_meta = scale_array_by_diagonal(S_meta)\n",
    "vis_S_meta = pd.DataFrame(corr_meta, columns=vis_df.columns, index=vis_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 1500\n",
    "height = 1500\n",
    "label_size = \"8pt\"\n",
    "lables_0, re_labels_0 = create_label_dict(vis_S)\n",
    "\n",
    "p0 = _make_heatmap(data=vis_S, labels_dict=lables_0, labels_dict_reversed=re_labels_0,\n",
    "                       title=\"Correlation: ASVs\", width=width, height=height,\n",
    "                       label_size=label_size)\n",
    "\n",
    "meta_corr = vis_S_meta.iloc[-n_cov:, -n_cov:]\n",
    "lables_1, re_labels_1 = create_label_dict(meta_corr)\n",
    "\n",
    "p1 = _make_heatmap(data=meta_corr, labels_dict=lables_1, labels_dict_reversed=re_labels_1,\n",
    "                       title=\"Correlation: covariates\", width=width, height=height,\n",
    "                       label_size=label_size)\n",
    "\n",
    "vis_S_meta = vis_S_meta.T\n",
    "\n",
    "n_cov = df.shape[1] - asv.shape[1]\n",
    "lables_2, re_labels_2 = create_label_dict(vis_S_meta)\n",
    "\n",
    "p2 = _make_heatmap(data=vis_S_meta, labels_dict=lables_2, labels_dict_reversed=re_labels_2,\n",
    "                       title=\"Correlation: ASVs + covariates\", width=width, height=height,\n",
    "                       label_size=label_size)\n",
    "\n",
    "show(p0)\n",
    "show(p1)\n",
    "show(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = asv.shape[0]\n",
    "p = asv.shape[1]\n",
    "print(\"Shape of data without covariates: {0}, {1}\".format(N, p))\n",
    "\n",
    "N_meta = df.shape[0]\n",
    "p_meta = df.shape[1]\n",
    "print(\"Shape of data with covariates: {0}, {1}\".format(N_meta, p_meta))\n",
    "\n",
    "#hyperparameters\n",
    "lambda1_range = np.logspace(0.5,-1.5,8)\n",
    "mu1_range = np.logspace(1.5,-0.2,6)\n",
    "\n",
    "modelselect_params = {'lambda1_range': lambda1_range, 'mu1_range': mu1_range}\n",
    "\n",
    "P_SGL = glasso_problem(corr, N, latent=False, do_scaling=False)\n",
    "P_SGL.model_selection(modelselect_params=modelselect_params, method='eBIC', gamma=0.2)\n",
    "\n",
    "P_SGL_low = glasso_problem(corr, N, latent=True, do_scaling=False)\n",
    "P_SGL_low.model_selection(modelselect_params=modelselect_params, method='eBIC', gamma=0.2)\n",
    "\n",
    "# create lambda matrix full of zeros\n",
    "shape_meta = (p_meta, p_meta)\n",
    "mask = np.zeros(shape_meta)\n",
    "# add small constant, so ADMM could converge\n",
    "mask = mask + 0.01\n",
    "# heavy penalize species\n",
    "n_bugs = len(asv.columns)\n",
    "bugs_block = np.ones((n_bugs, n_bugs))\n",
    "mask[0:n_bugs, 0:n_bugs] += bugs_block - 0.01\n",
    "lambda1_mask_exp = mask\n",
    "df_mask_exp = pd.DataFrame(lambda1_mask_exp, columns=vis_df.columns, index=vis_df.columns)\n",
    "\n",
    "modelselect_params[\"lambda1_mask\"] = lambda1_mask_exp\n",
    "P_SGL_adapt = glasso_problem(vis_S_meta.values, N_meta, latent=False, do_scaling=False)\n",
    "P_SGL_adapt.model_selection(modelselect_params=modelselect_params, method='eBIC', gamma=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SGL solution with lambda={lambda1} and mu={mu1}\".format(**P_SGL.reg_params))\n",
    "print(\"Adaptive SGL+low-rank solution with lambda={lambda1} and mu={mu1}\".format(**P_SGL_adapt.reg_params))\n",
    "print(\"SGL+low-rank solution with lambda={lambda1} and mu={mu1}\".format(**P_SGL_low.reg_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = P_SGL_low.solution.lowrank_\n",
    "r = np.linalg.matrix_rank(L)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_SGL.modelselect_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 1500\n",
    "height = 1500\n",
    "label_size = \"8pt\"\n",
    "\n",
    "# for visualization reasons we transform inverse covaraince to negative inverse covaraince, i.e., multiply by -1\n",
    "sgl = -1 * pd.DataFrame(P_SGL.solution.precision_, columns=asv_names, index=asv_names)\n",
    "adapt = -1 * pd.DataFrame(P_SGL_adapt.solution.precision_, columns=vis_df.columns, index=vis_df.columns)\n",
    "low = -1 * pd.DataFrame(P_SGL_low.solution.precision_, columns=asv_names, index=asv_names)\n",
    "\n",
    "\n",
    "lables_sgl, re_labels_sgl = create_label_dict(sgl)\n",
    "lables_adapt, re_labels_adapt = create_label_dict(adapt)\n",
    "lables_low, re_labels_low = create_label_dict(low)\n",
    "\n",
    "p_sgl = _make_heatmap(data=sgl, labels_dict=lables_sgl, labels_dict_reversed=re_labels_sgl,\n",
    "                       title=\"SGL estimated (negative) inverse covariance\", width=width, height=height,\n",
    "                       label_size=label_size)\n",
    "\n",
    "p_adapt = _make_heatmap(data=adapt, labels_dict=lables_adapt, labels_dict_reversed=re_labels_adapt,\n",
    "                       title=\"Adaptive estimated (negative) inverse covariance\", width=width, height=height,\n",
    "                       label_size=label_size)\n",
    "\n",
    "p_low = _make_heatmap(data=low, labels_dict=lables_low, labels_dict_reversed=re_labels_low,\n",
    "                       title=\"SGL+low-rank estimated (negative) inverse covariance\", width=width, height=height,\n",
    "                       label_size=label_size)\n",
    "show(p_sgl)\n",
    "show(p_adapt)\n",
    "show(p_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cols = list(adapt.iloc[:, -n_cov:].columns)\n",
    "asv95_sgl = [\"ASV_95\", \"ASV_24\", \"ASV_30\", \"ASV_31\", \"ASV_58\", \"ASV_66\", \"ASV_92\", \"ASV_102\", \"ASV_105\", \"ASV_111\"]\n",
    "asv95_low =[ \"ASV_95\", \"ASV_24\",           \"ASV_31\",           \"ASV_66\", \"ASV_92\",            \"ASV_105\", \"ASV_111\"]\n",
    "asv95_adapt = meta_cols + asv95_sgl\n",
    "\n",
    "sgl_edges = sgl[sgl.columns.intersection(asv95_sgl)].loc[asv95_sgl]\n",
    "adapt_edges = adapt[adapt.columns.intersection(asv95_adapt)].loc[asv95_adapt]\n",
    "low_edges = low[low.columns.intersection(asv95_low)].loc[asv95_low]\n",
    "\n",
    "\n",
    "G_SGL = create_graph(sgl_edges, threshold=0.1)\n",
    "G_adapt = create_graph(adapt_edges, threshold=0.1)\n",
    "G_low = create_graph(low_edges, threshold=0.1)\n",
    "\n",
    "\n",
    "# G_SGL = create_graph(sgl, threshold=0.1)\n",
    "# G_adapt = create_graph(adapt, threshold=0.1)\n",
    "# G_low = create_graph(low, threshold=0.1)\n",
    "\n",
    "\n",
    "width, height= 1000, 1000\n",
    "\n",
    "network_sgl = plot_network(G_SGL, title=\"SGL\", height=height, width=width)\n",
    "network_adapt = plot_network(G_adapt, title=\"Adaptive\",  height=height, width=width)\n",
    "network_low = plot_network(G_low, title=\"Low-rank\",  height=height, width=width)\n",
    "\n",
    "show(network_sgl)\n",
    "show(network_adapt)\n",
    "show(network_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_66_31 = scater_plot(vis_df[\"ASV_95\"], vis_df[\"ASV_58\"])\n",
    "p_18_temp = scater_plot(vis_df[\"ASV_95\"], vis_df[\"ph\"])\n",
    "p_51_temp = scater_plot(vis_df[\"ASV_58\"], vis_df[\"ph\"])\n",
    "\n",
    "show(p_66_31)\n",
    "show(p_18_temp)\n",
    "show(p_51_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = soil.T.copy()\n",
    "\n",
    "i = 1\n",
    "for col in raw.columns:\n",
    "    # length of ASVs identifier\n",
    "    if col.isdigit():\n",
    "        asv_name = \"ASV_{0}\".format(i)\n",
    "        raw.rename(columns={col: asv_name}, inplace=True)\n",
    "\n",
    "        i += 1\n",
    "        \n",
    "\n",
    "asv_66 = raw['ASV_95']\n",
    "asv_31 = raw['ASV_58']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asv_31.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asv_66.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(asv_66, asv_31, 'o', color='black');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_cov = adapt.iloc[:-n_cov, -n_cov:]\n",
    "\n",
    "L_adapt = inv_cov @ inv_cov.T\n",
    "L_adapt.shape\n",
    "\n",
    "L_1 = pd.DataFrame(P_SGL_low.solution.lowrank_, columns=asv_names, index=asv_names)\n",
    "L_2 = pd.DataFrame(L_adapt, columns=asv_names, index=asv_names)\n",
    "\n",
    "r1 = np.linalg.matrix_rank(L_1)\n",
    "r2 = np.linalg.matrix_rank(L_2)\n",
    "\n",
    "print(\"L1-rank: {0}\".format(r1))\n",
    "print(\"L2-rank: {0}\".format(r2))\n",
    "\n",
    "proj_1, loadings_1, eigv_1 = PCA(asv, L_1, inverse=True)\n",
    "\n",
    "eigv_sum_1 = np.sum(eigv_1)\n",
    "var_exp_1 = [(value / eigv_sum_1) for value in sorted(eigv_1, reverse=True)]\n",
    "\n",
    "proj_2, loadings_2, eigv_2 = PCA(asv, L_2, inverse=True)\n",
    "\n",
    "eigv_sum_2 = np.sum(eigv_2)\n",
    "var_exp_2 = [(value / eigv_sum_2) for value in sorted(eigv_2, reverse=True)]\n",
    "\n",
    "pca_plot = project_covariates(asv, metadata=meta_scaled, L=L_1, y='ph')\n",
    "show(pca_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 1500\n",
    "height = 1500\n",
    "label_size = \"8pt\"\n",
    "\n",
    "adapt_theta = adapt.copy()\n",
    "\n",
    "asv_cov = adapt_theta.iloc[:-n_cov, -n_cov:]\n",
    "\n",
    "l1_norm = np.linalg.norm(asv_cov.values, axis=1)\n",
    "\n",
    "adapt_theta['l1'] = np.append(l1_norm, np.zeros(n_cov))\n",
    "\n",
    "adapt_theta = adapt_theta.T\n",
    "\n",
    "adapt_theta['l1'] = np.append(l1_norm, np.zeros(n_cov+1))\n",
    "adapt_theta = adapt_theta.sort_values(by=['l1'], ascending=False)\n",
    "adapt_theta = adapt_theta.T\n",
    "adapt_theta = adapt_theta.sort_values(by=['l1'], ascending=False)\n",
    "\n",
    "lables_l1, re_labels_l1 = create_label_dict(adapt_theta)\n",
    "\n",
    "p_l1 = _make_heatmap(data=adapt_theta, labels_dict=lables_l1, labels_dict_reversed=re_labels_l1,\n",
    "                       title=\"Esatimated inverse covariance sorted by l1-norm of the covariates\", width=width, height=height,\n",
    "                       label_size=label_size)\n",
    "show(p_l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
