{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bisect\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "from itertools import chain\n",
    "from math import pi\n",
    "from sklearn import preprocessing\n",
    "from GGLasso.gglasso.problem import glasso_problem\n",
    "from utils import transform_features, scale_array_by_diagonal\n",
    "from utils import PCA\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.spatial import distance\n",
    "\n",
    "from networkx.utils import cuthill_mckee_ordering\n",
    "\n",
    "from bokeh.io import output_notebook, show, save\n",
    "from bokeh.models import Range1d, Circle, ColumnDataSource, MultiLine, HoverTool, LabelSet, PointDrawTool\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.plotting import from_networkx\n",
    "from bokeh.palettes import RdBu, Blues8\n",
    "from bokeh.models import HoverTool, Panel, Tabs, ColorBar, LinearColorMapper\n",
    "from bokeh.layouts import row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(X, L, inverse=True):\n",
    "    sig, V = np.linalg.eigh(L)\n",
    "\n",
    "    # sort eigenvalues in descending order\n",
    "    sig = sig[::-1]\n",
    "    V = V[:, ::-1]\n",
    "\n",
    "    ind = np.argwhere(sig > 1e-9)\n",
    "\n",
    "    if inverse:\n",
    "        loadings = V[:, ind] @ np.diag(np.sqrt(1 / sig[ind]))\n",
    "    else:\n",
    "        loadings = V[:, ind] @ np.diag(np.sqrt(sig[ind]))\n",
    "\n",
    "    # compute the projection\n",
    "    zu = X.values @ loadings\n",
    "\n",
    "    return zu, loadings, np.round(sig[ind].squeeze(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_heatmap(data: pd.DataFrame(), title: str = None, labels_dict: dict=None, labels_dict_reversed: dict=None,\n",
    "                  width: int = 1500, height: int = 1500, label_size: str = \"5pt\", not_low_rank: bool = True):\n",
    "    nlabels = len(labels_dict)\n",
    "    df = data.iloc[::-1] # rotate matrix 90 degrees\n",
    "    df = pd.DataFrame(df.stack(), columns=['covariance']).reset_index()\n",
    "    df.columns = [\"taxa_y\", \"taxa_x\", \"covariance\"]\n",
    "    if not_low_rank:\n",
    "        df = df.replace({\"taxa_x\": labels_dict, \"taxa_y\": labels_dict})\n",
    "\n",
    "    color_list, colors = _get_colors(df=df)\n",
    "    mapper = LinearColorMapper(palette=colors, low=-1, high=1)\n",
    "    color_bar = ColorBar(color_mapper=mapper, location=(0, 0))\n",
    "\n",
    "    bottom, top, left, right = _get_bounds(nlabels=nlabels)\n",
    "\n",
    "    source = ColumnDataSource(dict(top=top, bottom=bottom, left=left, right=right, color_list=color_list,\n",
    "                                   taxa_x=df['taxa_x'], taxa_y=df['taxa_y'], covariance=df['covariance']))\n",
    "\n",
    "    bokeh_tools = [\"save, zoom_in, zoom_out, wheel_zoom, box_zoom, crosshair, reset, hover\"]\n",
    "\n",
    "    p = figure(plot_width=width, plot_height=height, x_range=(0, nlabels), y_range=(0, nlabels),\n",
    "               title=title, title_location='above', x_axis_location=\"below\",\n",
    "               tools=bokeh_tools, toolbar_location='left')\n",
    "\n",
    "    p.quad(top=\"top\", bottom=\"bottom\", left=\"left\", right=\"right\", line_color='white', color=\"color_list\",\n",
    "           source=source)\n",
    "    p.xaxis.major_label_orientation = pi / 4\n",
    "    p.yaxis.major_label_orientation = \"horizontal\"\n",
    "    p.title.text_font_size = \"24pt\"\n",
    "    p.add_layout(color_bar, 'right')\n",
    "    p.toolbar.autohide = True\n",
    "\n",
    "    p.xaxis.ticker = list(range(0, nlabels))\n",
    "    p.yaxis.ticker = list(range(0, nlabels))\n",
    "    if not_low_rank:\n",
    "        p.xaxis.major_label_overrides = labels_dict\n",
    "        p.yaxis.major_label_overrides = labels_dict_reversed\n",
    "    p.xaxis.major_label_text_font_size = label_size\n",
    "    p.yaxis.major_label_text_font_size = label_size\n",
    "\n",
    "    hover = p.select(dict(type=HoverTool))\n",
    "    hover.tooltips = [\n",
    "        (\"taxa_x\", \"@taxa_x\"),\n",
    "        (\"taxa_y\", \"@taxa_y\"),\n",
    "        (\"covariance\", \"@covariance\"),\n",
    "    ]\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_network(G, title, width, height, node_size=None):\n",
    "    #Establish which categories will appear when hovering over each node\n",
    "    HOVER_TOOLTIPS = [(\"Character\", \"@index\")]\n",
    "    hover = HoverTool(tooltips=[('','@index')])\n",
    "    tools = [\"save, zoom_in, zoom_out, wheel_zoom, box_zoom, crosshair, reset, hover, pan\"]\n",
    "\n",
    "    #Create a plot â€” set dimensions, toolbar, and title\n",
    "    plot = figure(tooltips = HOVER_TOOLTIPS, plot_width=width, plot_height=height,\n",
    "                  tools=tools, active_scroll='wheel_zoom',\n",
    "                x_range=Range1d(-10.1, 10.1), \n",
    "                  y_range=Range1d(-10.1, 10.1), title=title)\n",
    "    \n",
    "    \n",
    "    \n",
    "    color_map = [\"#88CCEE\" if \"ASV\" in j else \"#DDCC77\" for j in G.nodes()] #green for bugs, and blue for covariates\n",
    "    nx.set_node_attributes(G, {j: {'color': color_map[i]} for i, j in enumerate(G.nodes())})\n",
    "\n",
    "    if node_size is not None:\n",
    "        n_degrees = {k: 15*v for k,v in G.degree()}\n",
    "        nx.set_node_attributes(G, n_degrees, 'node_size')\n",
    "        node_size = 'node_size'\n",
    "    else:\n",
    "        node_size = 40\n",
    "\n",
    "    network_graph = from_networkx(G, nx.spring_layout, scale=10, center=(0, 0))\n",
    "\n",
    "\n",
    "    #Set node size and color\n",
    "    network_graph.node_renderer.glyph = Circle(size=node_size,  fill_color=\"color\")\n",
    "    \n",
    "    #Set edge width and color\n",
    "    network_graph.edge_renderer.data_source.data[\"line_width\"] = [G.get_edge_data(a,b)['covariance']*10 for a, b in G.edges()]\n",
    "    network_graph.edge_renderer.data_source.data[\"line_color\"] = [\"#117733\" if G.get_edge_data(a, b)['covariance'] >= 0 else \"#CC6677\" for a, b in G.edges()]\n",
    "    network_graph.edge_renderer.glyph.line_width = {'field': 'line_width'}\n",
    "    network_graph.edge_renderer.glyph.line_color = {'field': 'line_color'}\n",
    "\n",
    "    #Add network graph to the plot\n",
    "    plot.renderers.append(network_graph)\n",
    "    \n",
    "    x, y = zip(*network_graph.layout_provider.graph_layout.values())\n",
    "    node_labels = list(G.nodes)\n",
    "    source = ColumnDataSource({'x': x, 'y': y, 'asv': [node_labels[i] for i in range(len(x))]})\n",
    "    labels = LabelSet(x='x', y='y', text='asv', x_offset=30, y_offset=-15, source=source, render_mode='canvas', text_font_size='12pt')\n",
    "\n",
    "    plot.renderers.append(labels)    \n",
    "\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_corr(corr_array, inplace=False):\n",
    "    \"\"\"\n",
    "    Rearranges the correlation matrix, corr_array, so that groups of highly \n",
    "    correlated variables are next to eachother \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    corr_array : pandas.DataFrame or numpy.ndarray\n",
    "        a NxN correlation matrix \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame or numpy.ndarray\n",
    "        a NxN correlation matrix with the columns and rows rearranged\n",
    "    \"\"\"\n",
    "    pairwise_distances = sch.distance.pdist(corr_array)\n",
    "    linkage = sch.linkage(pairwise_distances, method='complete')\n",
    "    cluster_distance_threshold = pairwise_distances.max()/2\n",
    "    idx_to_cluster_array = sch.fcluster(linkage, cluster_distance_threshold, \n",
    "                                        criterion='distance')\n",
    "    idx = np.argsort(idx_to_cluster_array)\n",
    "    \n",
    "    if not inplace:\n",
    "        corr_array = corr_array.copy()\n",
    "    \n",
    "    if isinstance(corr_array, pd.DataFrame):\n",
    "        return corr_array.iloc[idx, :].T.iloc[idx, :]\n",
    "    return corr_array[idx, :][:, idx]\n",
    "\n",
    "\n",
    "# fig = px.imshow(-1*cluster_corr(precision_SGL), color_continuous_scale='RdBu_r', zmin=-1, zmax=1)\n",
    "# fig.update_layout(margin = dict(t=100,r=100,b=100,l=100), width = 1000, height = 1000,\n",
    "#                  title='Clustered Estimated inverse covariance: ASVs', title_x=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(corr_matrix: pd.DataFrame(), threshold: float):\n",
    "    #take the upper part only\n",
    "    upper = np.triu(np.ones(corr_matrix.shape)).astype(bool)\n",
    "    df = corr_matrix.where(upper)\n",
    "    df = pd.DataFrame(corr_matrix.stack(), columns=['covariance']).reset_index()\n",
    "    df.columns = [\"source\", \"target\", \"covariance\"]\n",
    "    \n",
    "    #remove diagonal entries\n",
    "    #df = df[df['covariance'] <= threshold]\n",
    "    df = df[abs(df['covariance']) >= threshold]\n",
    "    #remove diagonal entries\n",
    "    df = df[df['source'] != df['target']]\n",
    "    #remove zero entries\n",
    "    df = df[df['covariance'] != 0]\n",
    "    \n",
    "    #build graph\n",
    "    G = nx.from_pandas_edgelist(df, edge_attr=\"covariance\")\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_covariates(counts=pd.DataFrame(), metadata=pd.DataFrame(), L=np.ndarray, y=str):\n",
    "    proj, loadings, eigv = PCA(counts.dropna(), L, inverse=True)\n",
    "    r = np.linalg.matrix_rank(L)\n",
    "    eigv_sum = np.sum(eigv)\n",
    "    var_exp = [(value / eigv_sum) for value in sorted(eigv, reverse=True)]\n",
    "    \n",
    "    depth = pd.DataFrame(data=raw.sum(axis=0), columns=[\"sequencing depth\"])\n",
    "    metadata = depth.join(metadata)\n",
    "    \n",
    "    pc_columns = list('PC{0} ({1}%)'.format(i+1, str(100 * var_exp[i])[:4]) for i in range(0, r))\n",
    "    df_proj = pd.DataFrame(proj, columns=pc_columns, index=counts.index)\n",
    "    df = df_proj.join(metadata)\n",
    "    \n",
    "    varName1 = 'PC1 ({0}%)'.format(str(100 * var_exp[0])[:4])\n",
    "    varName2 = y\n",
    "    df['x'] = df[varName1]\n",
    "    df['y'] = df[varName2]\n",
    "\n",
    "    source = ColumnDataSource(df)\n",
    "\n",
    "    p0 = figure(tools='save, zoom_in, zoom_out, wheel_zoom, box_zoom, reset', plot_width=800, plot_height=800,\n",
    "                active_scroll=\"wheel_zoom\",\n",
    "                x_axis_label=varName1, y_axis_label=varName2,\n",
    "                tooltips=[(varName1, \"@\" + varName1),\n",
    "                          (varName2, \"@\" + varName2)\n",
    "                          ],\n",
    "                title=varName1 + \" vs \" + varName2)\n",
    "\n",
    "    exp_cmap = LinearColorMapper(palette=Blues8[::-1], low=min(df['sequencing depth'].values), high=max(df['sequencing depth'].values))\n",
    "    p0.circle('x', 'y', source=source, size=15, line_color=None, fill_color={\"field\": \"sequencing depth\", \"transform\": exp_cmap}, fill_alpha=0.3)\n",
    "\n",
    "    color_bar_plot = figure(title='sequencing depth', title_location=\"right\",\n",
    "                            height=500, width=150, toolbar_location=None, min_border=0,\n",
    "                            outline_line_color=None)\n",
    "\n",
    "    bar = ColorBar(color_mapper=exp_cmap, location=(1, 1))\n",
    "\n",
    "    color_bar_plot.add_layout(bar, 'right')\n",
    "    color_bar_plot.title.align = \"center\"\n",
    "    color_bar_plot.title.text_font_size = '12pt'\n",
    "\n",
    "    layout = row(p0, color_bar_plot)\n",
    "\n",
    "    return layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_labels(df):\n",
    "    i = 1\n",
    "    for col in df.columns:\n",
    "        # length of ASVs identifier\n",
    "        if len(col) == 32:\n",
    "            asv_name = \"ASV_{0}\".format(i)\n",
    "            id_dict[asv_name] = col\n",
    "            df.rename(columns={col: asv_name}, inplace=True)\n",
    "\n",
    "            i += 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_bounds(nlabels: int):\n",
    "    bottom = list(chain.from_iterable([[ii] * nlabels for ii in range(nlabels)]))\n",
    "    top = list(chain.from_iterable([[ii + 1] * nlabels for ii in range(nlabels)]))\n",
    "    left = list(chain.from_iterable([list(range(nlabels)) for ii in range(nlabels)]))\n",
    "    right = list(chain.from_iterable([list(range(1, nlabels + 1)) for ii in range(nlabels)]))\n",
    "\n",
    "    return bottom, top, left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_colors(df: pd.DataFrame(), n_colors: int = 9):\n",
    "    colors = list(RdBu[n_colors])\n",
    "    ccorr = np.arange(-1, 1, 1 / (len(colors) / 2))\n",
    "    color_list = []\n",
    "    for value in df.covariance.values:\n",
    "        ind = bisect.bisect_left(ccorr, value) # smart array insertion\n",
    "        if ind == 0: # avoid ind == -1 on the next step\n",
    "            ind = ind + 1\n",
    "        color_list.append(colors[ind-1])\n",
    "    return color_list, colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_dict(df):\n",
    "    n_labels = len(df.columns)\n",
    "    labels_dict = dict(zip(range(n_labels), df.columns))\n",
    "    labels_dict_reversed = dict(zip(range(n_labels),list(labels_dict.values())[::-1]))\n",
    "    \n",
    "    return labels_dict, labels_dict_reversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scater_plot(x, y, width=800, height=600, size=3):\n",
    "    bokeh_tools = [\"save, zoom_in, zoom_out, wheel_zoom, box_zoom, crosshair, reset, hover\"]\n",
    "    p = figure(plot_width=width, plot_height=height, tools=bokeh_tools, toolbar_location='left')\n",
    "\n",
    "    source = ColumnDataSource({'x': x, 'y': y})\n",
    "\n",
    "    p.circle(\"x\", \"y\", size=size, source=source, line_color=None)\n",
    "\n",
    "    p.xaxis.axis_label = x.name\n",
    "    p.yaxis.axis_label = y.name\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count table\n",
    "raw = pd.read_csv('data/composition_feature-table.tsv', sep='\\t', index_col = 0)\n",
    "\n",
    "#clr-transformation\n",
    "clr = transform_features(raw, transformation=\"clr\")\n",
    "\n",
    "# covariates\n",
    "meta = pd.read_csv('data/acm_meta.tsv', sep='\\t', index_col = 0)\n",
    "\n",
    "# select only numeric features\n",
    "meta = meta.loc[:, meta.iloc[0, :] != 'categorical']\n",
    "meta = meta.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# drop QIIME2 header\n",
    "meta = meta.iloc[1:]\n",
    "# fill missing values with zeros\n",
    "meta = meta.fillna(0)\n",
    "\n",
    "#scale data\n",
    "scaler = preprocessing.StandardScaler().fit(meta)\n",
    "meta_scaled = scaler.transform(meta)\n",
    "meta_scaled = pd.DataFrame(meta_scaled, index=meta.index, columns=meta.columns)\n",
    "\n",
    "# transpose count data\n",
    "clr_T = clr.T\n",
    "# join by sample id\n",
    "df = clr_T.join(meta_scaled)\n",
    "\n",
    "# Rename long feature IDs with concise names\n",
    "vis_df = df.copy()\n",
    "id_dict = dict()\n",
    "vis_df = add_labels(vis_df)\n",
    "        \n",
    "#calculate covariance\n",
    "n_cov = meta_scaled.shape[1]\n",
    "asv = df.iloc[:, :-n_cov]\n",
    "S = np.cov(asv.T.values, bias=True)\n",
    "\n",
    "# correlation between ASVs ONLY\n",
    "corr = scale_array_by_diagonal(S)\n",
    "\n",
    "#add labels\n",
    "asv_names = vis_df.iloc[:, :-n_cov].columns\n",
    "vis_S = pd.DataFrame(corr, columns=asv_names, index=asv_names)\n",
    "\n",
    "# # correlation between ASVs and covariates\n",
    "S_meta = np.cov(df.T.values, bias=True)\n",
    "corr_meta = scale_array_by_diagonal(S_meta)\n",
    "vis_S_meta = pd.DataFrame(corr_meta, columns=vis_df.columns, index=vis_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 1500\n",
    "height = 1500\n",
    "label_size = \"8pt\"\n",
    "lables_0, re_labels_0 = create_label_dict(vis_S)\n",
    "\n",
    "p0 = _make_heatmap(data=vis_S, labels_dict=lables_0, labels_dict_reversed=re_labels_0,\n",
    "                       title=\"Correlation: ASVs\", width=width, height=height,\n",
    "                       label_size=label_size)\n",
    "\n",
    "meta_corr = vis_S_meta.iloc[-n_cov:, -n_cov:]\n",
    "lables_1, re_labels_1 = create_label_dict(meta_corr)\n",
    "\n",
    "p1 = _make_heatmap(data=meta_corr, labels_dict=lables_1, labels_dict_reversed=re_labels_1,\n",
    "                       title=\"Correlation: covariates\", width=width, height=height,\n",
    "                       label_size=label_size)\n",
    "\n",
    "# drop highly correlated covariates\n",
    "hcorr_cov = ['relative-humidity-soil-high', 'relative-humidity-soil-low', 'percent-relative-humidity-soil-100', 'temperature-soil-high', 'temperature-soil-low']\n",
    "\n",
    "for frame in [vis_S_meta, df, vis_df]:\n",
    "    frame.drop(hcorr_cov, axis=1, inplace=True)\n",
    "    frame.rename(columns={'average-soil-relative-humidity':'average humidity','average-soil-temperature': 'average temperature',}, inplace=True)\n",
    "\n",
    "vis_S_meta = vis_S_meta.T\n",
    "vis_S_meta.drop(hcorr_cov, axis=1, inplace=True)\n",
    "vis_S_meta.rename(columns={'average-soil-relative-humidity':'average humidity','average-soil-temperature': 'average temperature',}, inplace=True)\n",
    "\n",
    "n_cov = df.shape[1] - asv.shape[1]\n",
    "lables_2, re_labels_2 = create_label_dict(vis_S_meta)\n",
    "\n",
    "p2 = _make_heatmap(data=vis_S_meta, labels_dict=lables_2, labels_dict_reversed=re_labels_2,\n",
    "                       title=\"Correlation: ASVs + covariates\", width=width, height=height,\n",
    "                       label_size=label_size)\n",
    "\n",
    "show(p0)\n",
    "show(p1)\n",
    "show(p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data without covariates: 53, 130\n",
      "Shape of data with covariates: 53, 140\n",
      "ADMM terminated after 39 iterations with status: optimal.\n",
      "ADMM terminated after 25 iterations with status: optimal.\n",
      "ADMM terminated after 39 iterations with status: optimal.\n",
      "ADMM terminated after 10 iterations with status: optimal.\n",
      "ADMM terminated after 34 iterations with status: optimal.\n",
      "ADMM terminated after 11 iterations with status: optimal.\n",
      "ADMM terminated after 10 iterations with status: optimal.\n",
      "ADMM terminated after 21 iterations with status: optimal.\n",
      "ADMM terminated after 16 iterations with status: optimal.\n",
      "ADMM terminated after 23 iterations with status: optimal.\n",
      "ADMM terminated after 11 iterations with status: optimal.\n",
      "ADMM terminated after 9 iterations with status: optimal.\n",
      "ADMM terminated after 9 iterations with status: optimal.\n",
      "ADMM terminated after 28 iterations with status: optimal.\n",
      "ADMM terminated after 27 iterations with status: optimal.\n",
      "ADMM terminated after 12 iterations with status: optimal.\n",
      "ADMM terminated after 118 iterations with status: optimal.\n",
      "ADMM terminated after 11 iterations with status: optimal.\n",
      "ADMM terminated after 168 iterations with status: optimal.\n",
      "ADMM terminated after 242 iterations with status: optimal.\n",
      "ADMM terminated after 292 iterations with status: optimal.\n",
      "ADMM terminated after 630 iterations with status: optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: max iterations reached.\n",
      "ADMM terminated after 1000 iterations with status: max iterations reached.\n",
      "ADMM terminated after 1000 iterations with status: max iterations reached.\n",
      "ADMM terminated after 1000 iterations with status: max iterations reached.\n",
      "ADMM terminated after 1000 iterations with status: max iterations reached.\n",
      "ADMM terminated after 1000 iterations with status: max iterations reached.\n",
      "ADMM terminated after 22 iterations with status: optimal.\n",
      "ADMM terminated after 22 iterations with status: optimal.\n",
      "ADMM terminated after 21 iterations with status: optimal.\n",
      "ADMM terminated after 20 iterations with status: optimal.\n",
      "ADMM terminated after 20 iterations with status: optimal.\n",
      "ADMM terminated after 21 iterations with status: optimal.\n",
      "ADMM terminated after 22 iterations with status: optimal.\n",
      "ADMM terminated after 23 iterations with status: optimal.\n",
      "ADMM terminated after 24 iterations with status: optimal.\n",
      "ADMM terminated after 25 iterations with status: optimal.\n",
      "ADMM terminated after 34 iterations with status: optimal.\n",
      "ADMM terminated after 32 iterations with status: optimal.\n",
      "ADMM terminated after 29 iterations with status: optimal.\n",
      "ADMM terminated after 28 iterations with status: optimal.\n",
      "ADMM terminated after 26 iterations with status: optimal.\n",
      "ADMM terminated after 25 iterations with status: optimal.\n",
      "ADMM terminated after 25 iterations with status: optimal.\n",
      "ADMM terminated after 26 iterations with status: optimal.\n",
      "ADMM terminated after 26 iterations with status: optimal.\n",
      "ADMM terminated after 26 iterations with status: optimal.\n",
      "ADMM terminated after 120 iterations with status: optimal.\n",
      "ADMM terminated after 98 iterations with status: optimal.\n",
      "ADMM terminated after 89 iterations with status: optimal.\n",
      "ADMM terminated after 69 iterations with status: optimal.\n",
      "ADMM terminated after 64 iterations with status: optimal.\n",
      "ADMM terminated after 52 iterations with status: optimal.\n",
      "ADMM terminated after 43 iterations with status: optimal.\n",
      "ADMM terminated after 44 iterations with status: optimal.\n",
      "ADMM terminated after 44 iterations with status: optimal.\n",
      "ADMM terminated after 44 iterations with status: optimal.\n",
      "ADMM terminated after 168 iterations with status: optimal.\n",
      "ADMM terminated after 110 iterations with status: optimal.\n",
      "ADMM terminated after 110 iterations with status: optimal.\n",
      "ADMM terminated after 110 iterations with status: optimal.\n",
      "ADMM terminated after 110 iterations with status: optimal.\n",
      "ADMM terminated after 110 iterations with status: optimal.\n",
      "ADMM terminated after 89 iterations with status: optimal.\n",
      "ADMM terminated after 85 iterations with status: optimal.\n",
      "ADMM terminated after 77 iterations with status: optimal.\n",
      "ADMM terminated after 68 iterations with status: optimal.\n",
      "ADMM terminated after 243 iterations with status: optimal.\n",
      "ADMM terminated after 70 iterations with status: optimal.\n",
      "ADMM terminated after 68 iterations with status: optimal.\n",
      "ADMM terminated after 67 iterations with status: optimal.\n",
      "ADMM terminated after 67 iterations with status: optimal.\n",
      "ADMM terminated after 67 iterations with status: optimal.\n",
      "ADMM terminated after 67 iterations with status: optimal.\n",
      "ADMM terminated after 67 iterations with status: optimal.\n",
      "ADMM terminated after 67 iterations with status: optimal.\n",
      "ADMM terminated after 67 iterations with status: optimal.\n",
      "ADMM terminated after 292 iterations with status: optimal.\n",
      "ADMM terminated after 83 iterations with status: optimal.\n",
      "ADMM terminated after 80 iterations with status: optimal.\n",
      "ADMM terminated after 76 iterations with status: optimal.\n",
      "ADMM terminated after 75 iterations with status: optimal.\n",
      "ADMM terminated after 74 iterations with status: optimal.\n",
      "ADMM terminated after 73 iterations with status: optimal.\n",
      "ADMM terminated after 74 iterations with status: optimal.\n",
      "ADMM terminated after 74 iterations with status: optimal.\n",
      "ADMM terminated after 73 iterations with status: optimal.\n",
      "ADMM terminated after 630 iterations with status: optimal.\n",
      "ADMM terminated after 99 iterations with status: optimal.\n",
      "ADMM terminated after 97 iterations with status: optimal.\n",
      "ADMM terminated after 96 iterations with status: optimal.\n",
      "ADMM terminated after 96 iterations with status: optimal.\n",
      "ADMM terminated after 94 iterations with status: optimal.\n",
      "ADMM terminated after 93 iterations with status: optimal.\n",
      "ADMM terminated after 93 iterations with status: optimal.\n",
      "ADMM terminated after 92 iterations with status: optimal.\n",
      "ADMM terminated after 93 iterations with status: optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 148 iterations with status: optimal.\n",
      "ADMM terminated after 103 iterations with status: optimal.\n",
      "ADMM terminated after 101 iterations with status: optimal.\n",
      "ADMM terminated after 99 iterations with status: optimal.\n",
      "ADMM terminated after 97 iterations with status: optimal.\n",
      "ADMM terminated after 94 iterations with status: optimal.\n",
      "ADMM terminated after 93 iterations with status: optimal.\n",
      "ADMM terminated after 91 iterations with status: optimal.\n",
      "ADMM terminated after 89 iterations with status: optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 880 iterations with status: optimal.\n",
      "ADMM terminated after 79 iterations with status: optimal.\n",
      "ADMM terminated after 80 iterations with status: optimal.\n",
      "ADMM terminated after 78 iterations with status: optimal.\n",
      "ADMM terminated after 77 iterations with status: optimal.\n",
      "ADMM terminated after 76 iterations with status: optimal.\n",
      "ADMM terminated after 71 iterations with status: optimal.\n",
      "ADMM terminated after 70 iterations with status: optimal.\n",
      "ADMM terminated after 73 iterations with status: optimal.\n",
      "ADMM terminated after 1000 iterations with status: max iterations reached.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 424 iterations with status: optimal.\n",
      "ADMM terminated after 73 iterations with status: optimal.\n",
      "ADMM terminated after 74 iterations with status: optimal.\n",
      "ADMM terminated after 71 iterations with status: optimal.\n",
      "ADMM terminated after 72 iterations with status: optimal.\n",
      "ADMM terminated after 68 iterations with status: optimal.\n",
      "ADMM terminated after 69 iterations with status: optimal.\n",
      "ADMM terminated after 1000 iterations with status: max iterations reached.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 677 iterations with status: optimal.\n",
      "ADMM terminated after 71 iterations with status: optimal.\n",
      "ADMM terminated after 75 iterations with status: optimal.\n",
      "ADMM terminated after 74 iterations with status: optimal.\n",
      "ADMM terminated after 72 iterations with status: optimal.\n",
      "ADMM terminated after 71 iterations with status: optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 941 iterations with status: optimal.\n",
      "ADMM terminated after 79 iterations with status: optimal.\n",
      "ADMM terminated after 76 iterations with status: optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 277 iterations with status: optimal.\n",
      "ADMM terminated after 60 iterations with status: optimal.\n",
      "ADMM terminated after 1000 iterations with status: max iterations reached.\n",
      "ADMM terminated after 1000 iterations with status: max iterations reached.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: max iterations reached.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: max iterations reached.\n",
      "ADMM terminated after 1000 iterations with status: max iterations reached.\n",
      "ADMM terminated after 1000 iterations with status: max iterations reached.\n",
      "ADMM terminated after 1000 iterations with status: max iterations reached.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: primal optimal.\n",
      "ADMM terminated after 1000 iterations with status: max iterations reached.\n"
     ]
    }
   ],
   "source": [
    "N = asv.shape[0]\n",
    "p = asv.shape[1]\n",
    "print(\"Shape of data without covariates: {0}, {1}\".format(N, p))\n",
    "\n",
    "N_meta = df.shape[0]\n",
    "p_meta = df.shape[1]\n",
    "print(\"Shape of data with covariates: {0}, {1}\".format(N_meta, p_meta))\n",
    "\n",
    "#hyperparameters\n",
    "lambda1_range = np.logspace(0, -4, 15)\n",
    "mu1_range = np.logspace(0.9, 0.4, 10)\n",
    "modelselect_params = {'lambda1_range': lambda1_range, 'mu1_range': mu1_range}\n",
    "\n",
    "P_SGL = glasso_problem(corr, N, latent=False, do_scaling=False)\n",
    "P_SGL.model_selection(modelselect_params=modelselect_params, method='eBIC', gamma=0.1)\n",
    "\n",
    "P_SGL_low = glasso_problem(corr, N, latent=True, do_scaling=False)\n",
    "P_SGL_low.model_selection(modelselect_params=modelselect_params, method='eBIC', gamma=0.1)\n",
    "\n",
    "# create lambda matrix full of zeros\n",
    "shape_meta = (p_meta, p_meta)\n",
    "mask = np.zeros(shape_meta)\n",
    "# add small constant, so ADMM could converge\n",
    "mask = mask + 0.01\n",
    "# heavy penalize species\n",
    "n_bugs = len(asv.columns)\n",
    "bugs_block = np.ones((n_bugs, n_bugs))\n",
    "mask[0:n_bugs, 0:n_bugs] += bugs_block - 0.01\n",
    "lambda1_mask_exp = mask\n",
    "df_mask_exp = pd.DataFrame(lambda1_mask_exp, columns=vis_df.columns, index=vis_df.columns)\n",
    "\n",
    "modelselect_params[\"lambda1_mask\"] = lambda1_mask_exp\n",
    "P_SGL_adapt = glasso_problem(vis_S_meta.values, N_meta, latent=False, do_scaling=False)\n",
    "P_SGL_adapt.model_selection(modelselect_params=modelselect_params, method='eBIC', gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGL solution with lambda=0.2682695795279726 and mu=0\n",
      "Adaptive SGL+low-rank solution with lambda=0.2682695795279726 and mu=0\n",
      "SGL+low-rank solution with lambda=0.2682695795279726 and mu=3.686945064519575\n"
     ]
    }
   ],
   "source": [
    "print(\"SGL solution with lambda={lambda1} and mu={mu1}\".format(**P_SGL.reg_params))\n",
    "print(\"Adaptive SGL+low-rank solution with lambda={lambda1} and mu={mu1}\".format(**P_SGL_adapt.reg_params))\n",
    "print(\"SGL+low-rank solution with lambda={lambda1} and mu={mu1}\".format(**P_SGL_low.reg_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 1500\n",
    "height = 1500\n",
    "label_size = \"8pt\"\n",
    "\n",
    "# for visualization reasons we transform inverse covaraince to negative inverse covaraince, i.e., multiply by -1\n",
    "sgl = -1 * pd.DataFrame(P_SGL.solution.precision_, columns=asv_names, index=asv_names)\n",
    "adapt = -1 * pd.DataFrame(P_SGL_adapt.solution.precision_, columns=vis_df.columns, index=vis_df.columns)\n",
    "low = -1 * pd.DataFrame(P_SGL_low.solution.precision_, columns=asv_names, index=asv_names)\n",
    "\n",
    "\n",
    "lables_sgl, re_labels_sgl = create_label_dict(sgl)\n",
    "lables_adapt, re_labels_adapt = create_label_dict(adapt)\n",
    "lables_low, re_labels_low = create_label_dict(low)\n",
    "\n",
    "p_sgl = _make_heatmap(data=sgl, labels_dict=lables_sgl, labels_dict_reversed=re_labels_sgl,\n",
    "                       title=\"SGL estimated (negative) inverse covariance\", width=width, height=height,\n",
    "                       label_size=label_size)\n",
    "\n",
    "p_adapt = _make_heatmap(data=adapt, labels_dict=lables_adapt, labels_dict_reversed=re_labels_adapt,\n",
    "                       title=\"Adaptive estimated (negative) inverse covariance\", width=width, height=height,\n",
    "                       label_size=label_size)\n",
    "\n",
    "p_low = _make_heatmap(data=low, labels_dict=lables_low, labels_dict_reversed=re_labels_low,\n",
    "                       title=\"SGL+low-rank estimated (negative) inverse covariance\", width=width, height=height,\n",
    "                       label_size=label_size)\n",
    "show(p_sgl)\n",
    "show(p_adapt)\n",
    "show(p_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cols = list(adapt.iloc[:, -n_cov:].columns)\n",
    "asv18_edges = [\"ASV_18\", \"ASV_51\", \"ASV_46\", \"ASV_13\", \"ASV_7\", \"ASV_5\"]\n",
    "asv18_51 =[\"ASV_18\", \"ASV_51\"]\n",
    "asv18_edges_adapt = meta_cols + asv18_51\n",
    "\n",
    "sgl_edges = sgl[sgl.columns.intersection(asv18_edges)].loc[asv18_edges]\n",
    "adapt_edges = adapt[adapt.columns.intersection(asv18_edges_adapt)].loc[asv18_51]\n",
    "low_edges = low[low.columns.intersection(asv18_edges)].loc[asv18_edges]\n",
    "\n",
    "\n",
    "G_SGL = create_graph(sgl_edges, threshold=0.1)\n",
    "G_adapt = create_graph(adapt_edges, threshold=0.1)\n",
    "G_low = create_graph(low_edges, threshold=0.1)\n",
    "\n",
    "\n",
    "width, height= 1000, 1000\n",
    "\n",
    "network_sgl = plot_network(G_SGL, title=\"SGL\", height=height, width=width)\n",
    "network_adapt = plot_network(G_adapt, title=\"Adaptive\",  height=height, width=width)\n",
    "network_low = plot_network(G_low, title=\"Low-rank\",  height=height, width=width)\n",
    "\n",
    "show(network_sgl)\n",
    "show(network_adapt)\n",
    "show(network_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_18_51 = scater_plot(vis_df[\"ASV_18\"], vis_df[\"ASV_51\"])\n",
    "p_18_temp = scater_plot(vis_df[\"ASV_18\"], vis_df[\"average temperature\"])\n",
    "p_51_temp = scater_plot(vis_df[\"ASV_51\"], vis_df[\"average temperature\"])\n",
    "\n",
    "show(p_18_51)\n",
    "show(p_18_temp)\n",
    "show(p_51_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='3194', ...)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1-rank: 6\n",
      "L2-rank: 10\n"
     ]
    }
   ],
   "source": [
    "inv_cov = adapt.iloc[:-n_cov, -n_cov:]\n",
    "\n",
    "L_adapt = inv_cov @ inv_cov.T\n",
    "L_adapt.shape\n",
    "\n",
    "L_1 = pd.DataFrame(P_SGL_low.solution.lowrank_, columns=asv_names, index=asv_names)\n",
    "L_2 = pd.DataFrame(L_adapt, columns=asv_names, index=asv_names)\n",
    "\n",
    "r1 = np.linalg.matrix_rank(L_1)\n",
    "r2 = np.linalg.matrix_rank(L_2)\n",
    "\n",
    "print(\"L1-rank: {0}\".format(r1))\n",
    "print(\"L2-rank: {0}\".format(r2))\n",
    "\n",
    "proj_1, loadings_1, eigv_1 = PCA(asv, L_1, inverse=True)\n",
    "\n",
    "eigv_sum_1 = np.sum(eigv_1)\n",
    "var_exp_1 = [(value / eigv_sum_1) for value in sorted(eigv_1, reverse=True)]\n",
    "\n",
    "proj_2, loadings_2, eigv_2 = PCA(asv, L_2, inverse=True)\n",
    "\n",
    "eigv_sum_2 = np.sum(eigv_2)\n",
    "var_exp_2 = [(value / eigv_sum_2) for value in sorted(eigv_2, reverse=True)]\n",
    "\n",
    "pca_plot = project_covariates(asv, metadata=meta_scaled, L=L_1, y='average-soil-temperature')\n",
    "show(pca_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 1500\n",
    "height = 1500\n",
    "label_size = \"8pt\"\n",
    "\n",
    "adapt_theta = adapt.copy()\n",
    "\n",
    "asv_cov = adapt_theta.iloc[:-n_cov, -n_cov:]\n",
    "\n",
    "l1_norm = np.linalg.norm(asv_cov.values, axis=1)\n",
    "\n",
    "adapt_theta['l1'] = np.append(l1_norm, np.zeros(n_cov))\n",
    "\n",
    "adapt_theta = adapt_theta.T\n",
    "\n",
    "adapt_theta['l1'] = np.append(l1_norm, np.zeros(n_cov+1))\n",
    "adapt_theta = adapt_theta.sort_values(by=['l1'], ascending=False)\n",
    "adapt_theta = adapt_theta.T\n",
    "adapt_theta = adapt_theta.sort_values(by=['l1'], ascending=False)\n",
    "\n",
    "lables_l1, re_labels_l1 = create_label_dict(adapt_theta)\n",
    "\n",
    "p_l1 = _make_heatmap(data=adapt_theta, labels_dict=lables_l1, labels_dict_reversed=re_labels_l1,\n",
    "                       title=\"Esatimated inverse covariance sorted by l1-norm of the covariates\", width=width, height=height,\n",
    "                       label_size=label_size)\n",
    "show(p_l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_components = pd.DataFrame(loadings_1, index=low.index)\n",
    "pc_components = pc_components.iloc[::-1]\n",
    "pc_components.columns = [\"PC1\", \"PC2\", \"PC3\", \"PC4\", \"PC5\", \"PC6\"]\n",
    "\n",
    "# low-rank solution: r1=6\n",
    "identity = pd.DataFrame(np.eye(r1, r1), index=pc_components.columns, columns = pc_components.columns)\n",
    "# PCs are linearly independent by the definition\n",
    "pc_columns = pd.concat([pc_components, identity], axis=0)\n",
    "\n",
    "# inverse cov matrix extended by PCs\n",
    "asv_pc = pd.concat([low, pc_components], axis=1)\n",
    "asv_pc = pd.concat([asv_pc.T, pc_columns], axis=1)\n",
    "\n",
    "asv_low = asv_pc.iloc[:-r1, -r1:]\n",
    "# l1-norm of partial correlation between ASVs and PCs\n",
    "l1_norm_pc = np.linalg.norm(asv_low.values, axis=1)\n",
    "\n",
    "asv_pc['l1'] = np.append(l1_norm_pc, np.zeros(r1))\n",
    "asv_pc = asv_pc.T\n",
    "asv_pc['l1'] = np.append(l1_norm_pc, np.zeros(r1 + 1))\n",
    "\n",
    "#sorting by the order of adaptive l1-norm sorted solution\n",
    "n_asvs = len(vis_S)\n",
    "sorted_asv = asv_pc.iloc[:n_asvs, :].reindex(index=adapt_theta.iloc[:n_asvs, :].index)\n",
    "sorted_asv_pc = sorted_asv.T.join(asv_pc.iloc[:, -7:])\n",
    "sorted_asv = sorted_asv_pc.iloc[:n_asvs, :].reindex(index=adapt_theta.iloc[:n_asvs, :].index)\n",
    "sorted_ = pd.concat([sorted_asv_pc, sorted_asv_pc.iloc[n_asvs:, :]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASV_56</th>\n",
       "      <th>ASV_69</th>\n",
       "      <th>ASV_61</th>\n",
       "      <th>ASV_24</th>\n",
       "      <th>ASV_48</th>\n",
       "      <th>ASV_17</th>\n",
       "      <th>ASV_18</th>\n",
       "      <th>ASV_5</th>\n",
       "      <th>ASV_7</th>\n",
       "      <th>ASV_30</th>\n",
       "      <th>...</th>\n",
       "      <th>ASV_89</th>\n",
       "      <th>ASV_94</th>\n",
       "      <th>ASV_108</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>l1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ASV_56</th>\n",
       "      <td>-2.542841</td>\n",
       "      <td>1.023335</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.511900</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.219404</td>\n",
       "      <td>0.095811</td>\n",
       "      <td>0.181287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087718</td>\n",
       "      <td>-0.053073</td>\n",
       "      <td>-0.356884</td>\n",
       "      <td>-0.032680</td>\n",
       "      <td>0.036390</td>\n",
       "      <td>-0.010152</td>\n",
       "      <td>0.374664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASV_69</th>\n",
       "      <td>1.023335</td>\n",
       "      <td>-2.707712</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.544160</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187058</td>\n",
       "      <td>0.102231</td>\n",
       "      <td>0.160393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087580</td>\n",
       "      <td>-0.058583</td>\n",
       "      <td>-0.360018</td>\n",
       "      <td>-0.034892</td>\n",
       "      <td>0.036347</td>\n",
       "      <td>-0.011368</td>\n",
       "      <td>0.378659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASV_61</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-1.197447</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060143</td>\n",
       "      <td>-0.001304</td>\n",
       "      <td>0.005161</td>\n",
       "      <td>0.070309</td>\n",
       "      <td>-0.040194</td>\n",
       "      <td>-0.063387</td>\n",
       "      <td>0.119257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASV_24</th>\n",
       "      <td>0.511900</td>\n",
       "      <td>0.544160</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-2.256941</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.614774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.032354</td>\n",
       "      <td>0.007758</td>\n",
       "      <td>-0.353691</td>\n",
       "      <td>0.022901</td>\n",
       "      <td>0.053749</td>\n",
       "      <td>0.058024</td>\n",
       "      <td>0.364671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASV_48</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-1.717886</td>\n",
       "      <td>0.257549</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008263</td>\n",
       "      <td>-0.007555</td>\n",
       "      <td>-0.001656</td>\n",
       "      <td>0.054961</td>\n",
       "      <td>-0.022060</td>\n",
       "      <td>-0.155032</td>\n",
       "      <td>0.166345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC3</th>\n",
       "      <td>-0.356884</td>\n",
       "      <td>-0.360018</td>\n",
       "      <td>0.005161</td>\n",
       "      <td>-0.353691</td>\n",
       "      <td>-0.001656</td>\n",
       "      <td>0.010129</td>\n",
       "      <td>-0.297899</td>\n",
       "      <td>-0.272277</td>\n",
       "      <td>-0.320224</td>\n",
       "      <td>-0.224709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.001551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC4</th>\n",
       "      <td>-0.032680</td>\n",
       "      <td>-0.034892</td>\n",
       "      <td>0.070309</td>\n",
       "      <td>0.022901</td>\n",
       "      <td>0.054961</td>\n",
       "      <td>0.156797</td>\n",
       "      <td>-0.105555</td>\n",
       "      <td>-0.255562</td>\n",
       "      <td>0.071052</td>\n",
       "      <td>-0.028295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054248</td>\n",
       "      <td>0.054553</td>\n",
       "      <td>0.055826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC5</th>\n",
       "      <td>0.036390</td>\n",
       "      <td>0.036347</td>\n",
       "      <td>-0.040194</td>\n",
       "      <td>0.053749</td>\n",
       "      <td>-0.022060</td>\n",
       "      <td>-0.081940</td>\n",
       "      <td>-0.020311</td>\n",
       "      <td>0.077947</td>\n",
       "      <td>0.120317</td>\n",
       "      <td>0.073931</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003981</td>\n",
       "      <td>-0.004081</td>\n",
       "      <td>-0.004497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC6</th>\n",
       "      <td>-0.010152</td>\n",
       "      <td>-0.011368</td>\n",
       "      <td>-0.063387</td>\n",
       "      <td>0.058024</td>\n",
       "      <td>-0.155032</td>\n",
       "      <td>-0.235219</td>\n",
       "      <td>0.059634</td>\n",
       "      <td>-0.150916</td>\n",
       "      <td>0.085373</td>\n",
       "      <td>0.033543</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132234</td>\n",
       "      <td>-0.132474</td>\n",
       "      <td>-0.133475</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1</th>\n",
       "      <td>0.374664</td>\n",
       "      <td>0.378659</td>\n",
       "      <td>0.119257</td>\n",
       "      <td>0.364671</td>\n",
       "      <td>0.166345</td>\n",
       "      <td>0.299832</td>\n",
       "      <td>0.424731</td>\n",
       "      <td>0.422329</td>\n",
       "      <td>0.385495</td>\n",
       "      <td>0.372699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144393</td>\n",
       "      <td>0.144789</td>\n",
       "      <td>0.146446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows Ã— 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ASV_56    ASV_69    ASV_61    ASV_24    ASV_48    ASV_17    ASV_18  \\\n",
       "ASV_56 -2.542841  1.023335 -0.000000  0.511900 -0.000000 -0.000000  0.000000   \n",
       "ASV_69  1.023335 -2.707712 -0.000000  0.544160 -0.000000 -0.000000  0.000000   \n",
       "ASV_61 -0.000000 -0.000000 -1.197447 -0.000000  0.000000  0.000000 -0.000000   \n",
       "ASV_24  0.511900  0.544160 -0.000000 -2.256941 -0.000000 -0.000000  0.000000   \n",
       "ASV_48 -0.000000 -0.000000  0.000000 -0.000000 -1.717886  0.257549 -0.000000   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "PC3    -0.356884 -0.360018  0.005161 -0.353691 -0.001656  0.010129 -0.297899   \n",
       "PC4    -0.032680 -0.034892  0.070309  0.022901  0.054961  0.156797 -0.105555   \n",
       "PC5     0.036390  0.036347 -0.040194  0.053749 -0.022060 -0.081940 -0.020311   \n",
       "PC6    -0.010152 -0.011368 -0.063387  0.058024 -0.155032 -0.235219  0.059634   \n",
       "l1      0.374664  0.378659  0.119257  0.364671  0.166345  0.299832  0.424731   \n",
       "\n",
       "           ASV_5     ASV_7    ASV_30  ...    ASV_89    ASV_94   ASV_108  \\\n",
       "ASV_56  0.219404  0.095811  0.181287  ...  0.000000  0.000000  0.000000   \n",
       "ASV_69  0.187058  0.102231  0.160393  ...  0.000000  0.000000  0.000000   \n",
       "ASV_61 -0.000000 -0.000000 -0.000000  ...  0.000000  0.000000  0.000000   \n",
       "ASV_24  0.000000  0.614774  0.000000  ... -0.000000 -0.000000 -0.000000   \n",
       "ASV_48 -0.000000 -0.000000 -0.000000  ...  0.000000  0.000000  0.000000   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "PC3    -0.272277 -0.320224 -0.224709  ...  0.001317  0.001362  0.001551   \n",
       "PC4    -0.255562  0.071052 -0.028295  ...  0.054248  0.054553  0.055826   \n",
       "PC5     0.077947  0.120317  0.073931  ... -0.003981 -0.004081 -0.004497   \n",
       "PC6    -0.150916  0.085373  0.033543  ... -0.132234 -0.132474 -0.133475   \n",
       "l1      0.422329  0.385495  0.372699  ...  0.144393  0.144789  0.146446   \n",
       "\n",
       "             PC1       PC2       PC3       PC4       PC5       PC6        l1  \n",
       "ASV_56  0.087718 -0.053073 -0.356884 -0.032680  0.036390 -0.010152  0.374664  \n",
       "ASV_69  0.087580 -0.058583 -0.360018 -0.034892  0.036347 -0.011368  0.378659  \n",
       "ASV_61  0.060143 -0.001304  0.005161  0.070309 -0.040194 -0.063387  0.119257  \n",
       "ASV_24 -0.032354  0.007758 -0.353691  0.022901  0.053749  0.058024  0.364671  \n",
       "ASV_48  0.008263 -0.007555 -0.001656  0.054961 -0.022060 -0.155032  0.166345  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "PC3     0.000000  0.000000  1.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "PC4     0.000000  0.000000  0.000000  1.000000  0.000000  0.000000  0.000000  \n",
       "PC5     0.000000  0.000000  0.000000  0.000000  1.000000  0.000000  0.000000  \n",
       "PC6     0.000000  0.000000  0.000000  0.000000  0.000000  1.000000  0.000000  \n",
       "l1      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[137 rows x 137 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = asv_pc.iloc[:130, :].reindex(index=adapt_theta.iloc[:130, :].index)\n",
    "test_1 = test.T.join(asv_pc.iloc[:, -7:])\n",
    "test_2 = test_1.iloc[:130, :].reindex(index=adapt_theta.iloc[:130, :].index)\n",
    "test_3 = pd.concat([test_2, test_1.iloc[130:, :]], axis=0)\n",
    "test_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "lables_l1_low, re_labels_l1_low = create_label_dict(test_3)\n",
    "\n",
    "p_l1_low = _make_heatmap(data=test_3, labels_dict=lables_l1_low, labels_dict_reversed=re_labels_l1_low,\n",
    "                       title=\"Esatimated inverse covariance (sparse + low-rank) sorted by l1-norm of the PCs\", width=width, height=height,\n",
    "                       label_size=label_size)\n",
    "show(p_l1_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
