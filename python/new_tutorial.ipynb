{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from GGLasso.gglasso.problem import glasso_problem\n",
    "from utils import transform_features, scale_array_by_diagonal\n",
    "from utils import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv('data/composition_feature-table.tsv', sep='\\t', index_col = 0)\n",
    "\n",
    "print(raw.shape)\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw.to_csv(\"data/count_table.csv\", index=True)\n",
    "raw.iloc[:, 0].plot.hist(bins=24, alpha=1).get_figure().savefig('plots/raw_count.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr = transform_features(raw, transformation=\"clr\")\n",
    "clr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr.iloc[:, 0].plot.hist(bins=24, alpha=1).get_figure().savefig('plots/clr_count.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modified CLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mclr = transform_features(raw, transformation=\"mclr\")\n",
    "mclr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mclr.iloc[:, 0].plot.hist(bins=24, alpha=1).get_figure().savefig('plots/mclr_count.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covariates\n",
    "meta = pd.read_csv('data/acm_meta.tsv', sep='\\t', index_col = 0)\n",
    "\n",
    "# select only numeric features\n",
    "meta = meta.loc[:, meta.iloc[0, :] != 'categorical']\n",
    "meta = meta.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# drop QIIME2 header\n",
    "meta = meta.iloc[1:]\n",
    "# fill missing values with zeros\n",
    "meta = meta.fillna(0)\n",
    "\n",
    "print(meta.shape)\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(5,3,figsize=(15, 20))\n",
    "meta.hist(ax=axis)\n",
    "\n",
    "# fig.savefig('plots/meta_unscaled.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(meta)\n",
    "meta_scaled = scaler.transform(meta)\n",
    "\n",
    "meta_scaled = pd.DataFrame(meta_scaled, index=meta.index, columns=meta.columns)\n",
    "meta_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(5,3,figsize=(15, 20))\n",
    "meta_scaled.hist(ax=axis)\n",
    "\n",
    "# fig.savefig('plots/meta_scaled.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge data with covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # transpose count data\n",
    "# mclr_T = mclr.T\n",
    "# # join by sample id\n",
    "# df = mclr_T.join(meta_scaled)\n",
    "\n",
    "# transpose count data\n",
    "clr_T = clr.T\n",
    "# join by sample id\n",
    "df = clr_T.join(meta_scaled)\n",
    "\n",
    "#check if any missing values\n",
    "print(\"Any missing values?: {0}\".format(df.isnull().sum().any()))\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename long feature IDs with concise names\n",
    "vis_df = df.copy()\n",
    "id_dict = dict()\n",
    "\n",
    "i = 1\n",
    "for col in vis_df.columns:\n",
    "    # length of ASVs identifier\n",
    "    if len(col) == 32:\n",
    "        asv_name = \"ASV_{0}\".format(i)\n",
    "        id_dict[asv_name] = col\n",
    "        vis_df.rename(columns={col: asv_name}, inplace=True)\n",
    "        \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cov = meta_scaled.shape[1]\n",
    "asv = df.iloc[:, :-n_cov]\n",
    "S = np.cov(asv.T.values, bias=True)\n",
    "\n",
    "# correlation between ASVs ONLY\n",
    "corr = scale_array_by_diagonal(S)\n",
    "\n",
    "asv_names = vis_df.iloc[:, :-n_cov].columns\n",
    "vis_S = pd.DataFrame(corr, columns=asv_names, index=asv_names)\n",
    "print(vis_S.shape)\n",
    "vis_S.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(vis_S, color_continuous_scale='RdBu_r', zmin=-1, zmax=1)\n",
    "fig.update_layout(margin = dict(t=100,r=100,b=100,l=100), width = 1000, height = 1000,\n",
    "                 title='Correlation: ASVs', title_x=0.5)\n",
    "\n",
    "# fig.write_image(\"plots/asv_correlation.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_meta = np.cov(df.T.values, bias=True)\n",
    "\n",
    "# correlation between ASVs and covariates\n",
    "corr_meta = scale_array_by_diagonal(S_meta)\n",
    "\n",
    "vis_S_meta = pd.DataFrame(corr_meta, columns=vis_df.columns, index=vis_df.columns)\n",
    "print(vis_S_meta.shape)\n",
    "vis_S_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(vis_S_meta, color_continuous_scale='RdBu_r', zmin=-1, zmax=1)\n",
    "fig.update_layout(margin = dict(t=100,r=100,b=100,l=100), width = 1000, height = 1000,\n",
    "                 title='Covariance: ASVs and covariates', title_x=0.5)\n",
    "\n",
    "# fig.write_image(\"plots/asv_and_covariates_correlation.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = asv.shape[0]\n",
    "p = asv.shape[1]\n",
    "print(\"Shape of data without covariates: {0}, {1}\".format(N, p))\n",
    "\n",
    "N_meta = df.shape[0]\n",
    "p_meta = df.shape[1]\n",
    "print(\"Shape of data with covariates: {0}, {1}\".format(N_meta, p_meta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Statement 1**:\n",
    "\n",
    "We know that environment has a large impact on microbial composition.\n",
    "We would like to investigate this effect and run single graphical lasso model while accounting for latent components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGL + low-rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda1_range = np.logspace(0, -4, 15)\n",
    "mu1_range = np.logspace(2, -1, 10)\n",
    "\n",
    "modelselect_params = {'lambda1_range': lambda1_range, 'mu1_range': mu1_range}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_SGL_low = glasso_problem(corr, N, latent=True, do_scaling=False)\n",
    "print(P_SGL_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_SGL_low.model_selection(modelselect_params=modelselect_params, method='eBIC', gamma=0.1)\n",
    "print(P_SGL_low.reg_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stat in ['AIC', 'SP', 'RANK', 'LAMBDA', 'MU', 'BEST']:\n",
    "    print(stat)\n",
    "    print(P_SGL_low.modelselect_stats[stat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_SGL_low = pd.DataFrame(P_SGL_low.solution.precision_, columns=asv_names, index=asv_names)\n",
    "\n",
    "fig = px.imshow(-1*precision_SGL_low, color_continuous_scale='RdBu_r', zmin=-1, zmax=1)\n",
    "fig.update_layout(margin = dict(t=100,r=100,b=100,l=100), width = 1000, height = 1000,\n",
    "                 title='Estimated inverse covariance: ASVs', title_x=0.5)\n",
    "\n",
    "# fig.write_image(\"plots/sgl_asv_only.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = pd.DataFrame(P_SGL_low.solution.lowrank_, columns=asv_names, index=asv_names)\n",
    "\n",
    "print(\"Rank: {0}\".format(np.linalg.matrix_rank(L)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- **Statement 2**:\n",
    "\n",
    "According to the models selection statistics, the chosen optimal hyperparameters lay in the middle of the grid and we have reached a global minimum of our function. Yet we can try to find such hyperparameters which give us low-rank solutions with the rank of our interest, e.g., from 0 to 10 as well as desired data sparsity level. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda1_range = [0.07]\n",
    "# mu1_range = [1.8, 1.55, 1.4, 1.2, 1.18, 1.1, 1.09, 1.05, 1.015, 1]\n",
    "\n",
    "# modelselect_params = {'lambda1_range': lambda1_range, 'mu1_range': mu1_range}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P_SGL_low_tuned = glasso_problem(corr, N, latent=True, do_scaling=False)\n",
    "# print(P_SGL_low_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P_SGL_low_tuned.model_selection(modelselect_params=modelselect_params, method='eBIC', gamma=0.1)\n",
    "# print(P_SGL_low_tuned.reg_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for stat in ['AIC', 'SP', 'RANK', 'MU', 'BEST']:\n",
    "#     print(stat)\n",
    "#     print(P_SGL_low_tuned.modelselect_stats[stat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L_tuned = pd.DataFrame(P_SGL_low_tuned.solution.lowrank_, columns=asv_names, index=asv_names)\n",
    "\n",
    "# rank = np.linalg.matrix_rank(L_tuned)\n",
    "# print(\"Rank: {0}\".format(rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.imshow(L_tuned, color_continuous_scale='RdBu_r', zmin=-1, zmax=1)\n",
    "# fig.update_layout(margin = dict(t=100,r=100,b=100,l=100), width = 1000, height = 1000,\n",
    "#                  title='Low-rank: ASVs', title_x=0.5)\n",
    "\n",
    "# fig.write_image(\"plots/low_rank_asv_only.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Statement 3**:\n",
    "\n",
    "Imagine we don't have covariate information.\n",
    "\n",
    "The Graphical Lasso solution is of the form Î˜âˆ’ð¿ where Î˜ is sparse and ð¿ has low rank. We use the low rank component of the Graphical Lasso solution in order to do a robust PCA. For this, we use the eigendecomposition ð¿=ð‘‰Î£ð‘‰ð‘‡ where the columns of ð‘‰ are the orthonormal eigenvecors and Î£ is diagonal containing the eigenvalues. Denote the columns of ð‘‰ corresponding only to positive eigenvalues with ð‘‰Ìƒ âˆˆâ„ð‘Ã—ð‘Ÿ and Î£Ìƒ âˆˆâ„ð‘ŸÃ—ð‘Ÿ accordingly, where ð‘Ÿ=rank(ð¿). Then we have ð¿=ð‘‰Ìƒ Î£Ìƒ ð‘‰Ìƒ ð‘‡.\n",
    "Now we project the data matrix ð‘‹âˆˆâ„ð‘Ã—ð‘ onto the eigenspaces of ð¿âˆ’1 - which are the same as of ð¿ - by computing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proj, loadings, eigv = PCA(asv, L_tuned, inverse=True)\n",
    "proj, loadings, eigv = PCA(asv, L, inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = raw.sum(axis=0)\n",
    "ph = vis_df[\"ph\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "im = ax.scatter(proj[:,0], ph, c = depth, cmap = plt.cm.Blues, vmin = 0)\n",
    "cbar = fig.colorbar(im)\n",
    "cbar.set_label(\"Sampling depth\")\n",
    "ax.set_xlabel(f\"PCA component 1 with eigenvalue {eigv[0]}\")\n",
    "ax.set_ylabel(\"pH\")\n",
    "\n",
    "print(\"Spearman correlation between pH and 1st component: {0}, p-value: {1}\".format(stats.spearmanr(ph, proj[:,0])[0],\n",
    "                                                                              stats.spearmanr(ph, proj[:,0])[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Statement 4**:\n",
    "\n",
    "Alternatively, we could solve SGL with adaptive penalization and covariance matrix where covariates are included. So, we could see if loading vectors of PCA we found with the previous model where was no information about covariates are correlated with the solution where we include covariate information. Thus, we could argue that SGL model with low-rank component can capture the information which is unknown but important for microbial composition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGL with covariates and adaptive penalization procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lambda matrix full of zeros\n",
    "shape_meta = (p_meta, p_meta)\n",
    "mask = np.zeros(shape_meta)\n",
    "\n",
    "# add small constant, so ADMM could converge\n",
    "mask = mask + 0.01\n",
    "\n",
    "# heavy penalize species\n",
    "n_bugs = len(asv.columns)\n",
    "bugs_block = np.ones((n_bugs, n_bugs))\n",
    "mask[0:n_bugs, 0:n_bugs] += bugs_block - 0.01\n",
    "lambda1_mask_exp = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda1_mask_exp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mask_exp = pd.DataFrame(lambda1_mask_exp, columns=vis_df.columns, index=vis_df.columns)\n",
    "\n",
    "fig = px.imshow(df_mask_exp, color_continuous_scale='RdBu_r')\n",
    "fig.update_layout(margin = dict(t=100,r=100,b=100,l=100), width = 1000, height = 1000,\n",
    "                 title='Lambda-mask matrix: weights before the penalization term', title_x=0.5)\n",
    "\n",
    "fig.add_annotation(text=\"$\\lambda=1$\",\n",
    "                  xref=\"paper\", yref=\"paper\", font=dict(color='yellow',size=155),\n",
    "                  x=0.5, y=0.5, showarrow=False)\n",
    "fig.add_annotation(text=\"$\\lambda=0.01$\",\n",
    "                  xref=\"paper\", yref=\"paper\", font=dict(color='yellow',size=155),\n",
    "                  x=0.5, y=0.05, showarrow=False)\n",
    "\n",
    "fig.update_coloraxes(showscale=False)\n",
    "\n",
    "# fig.write_image(\"plots/lambda_mask.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### the same default grid, no tuning\n",
    "lambda1_range = np.logspace(0, -4, 15)\n",
    "\n",
    "### less sparsity in ASVs block\n",
    "# lambda1_range = np.logspace(-0.5, -1, 15)\n",
    "\n",
    "modelselect_params = {'lambda1_range': lambda1_range, 'lambda1_mask': lambda1_mask_exp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_SGL_adapt = glasso_problem(corr_meta, N_meta, latent=False, do_scaling=False)\n",
    "print(P_SGL_adapt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_SGL_adapt.model_selection(modelselect_params=modelselect_params, method='eBIC', gamma=0.1)\n",
    "print(P_SGL_adapt.reg_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: mu1=0, i.e., no low-rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stat in ['AIC', 'SP', 'LAMBDA', 'BEST']:\n",
    "    print(stat)\n",
    "    print(P_SGL_adapt.modelselect_stats[stat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_adapt = pd.DataFrame(P_SGL_adapt.solution.precision_, columns=vis_df.columns, index=vis_df.columns)\n",
    "precision_adapt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(-1*precision_adapt, color_continuous_scale='RdBu_r', zmin=-1, zmax=1)\n",
    "fig.update_layout(margin = dict(t=100,r=100,b=100,l=100), width = 1000, height = 1000,\n",
    "                 title='Esatimated inverse covariance (adaptive)', title_x=0.5)\n",
    "# fig.write_image(\"plots/sgl_asv_and_cov.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_cov = precision_adapt.iloc[:-n_cov, -n_cov:]\n",
    "\n",
    "fig = px.imshow(inv_cov, color_continuous_scale='RdBu_r', zmin=-1, zmax=1)\n",
    "fig.update_layout(margin = dict(t=100,r=100,b=100,l=100), width = 600, height = 3000,\n",
    "                 title='Negative inverse covariance between ASVs and covariates', title_x=0.5)\n",
    "\n",
    "# fig.write_image(\"plots/sgl_cov.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = loadings.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(3, 15, figsize=(200, 50))\n",
    "\n",
    "# j = 0\n",
    "# for col in inv_cov.columns:\n",
    "\n",
    "#     for i in range(0, rank):\n",
    "#         spearman_r = stats.spearmanr(inv_cov[col], loadings[:, i])\n",
    "#         if abs(spearman_r[0]) > 0.4:\n",
    "#             print(\"Spearman correlation between estimated pH and {0}th principal axis: {1}, \\n\\t p-value: {2}\".format(\n",
    "#             axis, spearman_r[0], spearman_r[1]))\n",
    "            \n",
    "        \n",
    "#         ax[i][j].scatter(loadings[:,i], inv_cov[col])\n",
    "#         ax[i][j].set_xlabel(\"Principal axis (loading vector) {0}\".format(i))\n",
    "#         ax[i][j].set_ylabel(\"{0}\".format(col))\n",
    "\n",
    "        \n",
    "#     j += 1\n",
    "    \n",
    "# plt.savefig(\"plots/big_scatter.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Statement 5**:\n",
    "\n",
    "Now we would like to test if the latent components of our solution can explain the covariates.\n",
    "\n",
    "On the left-hand subplot, we project estimated covariates to the low-rank solution.\n",
    "On the right-hand subplot, we project original covariates to the same low-rank solution where no covariates were included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot PCs vs covariates\n",
    "\n",
    "eigv_sum = np.sum(eigv)\n",
    "var_exp = [(value / eigv_sum) for value in sorted(eigv, reverse=True)]\n",
    "\n",
    "x = raw.sum(axis=0)\n",
    "seq_depth = pd.DataFrame(data=x, columns=[\"sequencing depth\"])\n",
    "\n",
    "test_df = vis_df.copy()\n",
    "test_df = test_df.join(seq_depth)\n",
    "\n",
    "for col in meta_scaled.columns:\n",
    "\n",
    "    for i in range(0, rank):\n",
    "\n",
    "        r_2 = stats.spearmanr(test_df[col], proj[:, i])[0]\n",
    "        p_value = stats.spearmanr(test_df[col], proj[:, i])[1]\n",
    "        \n",
    "        if abs(r_2) > 0.6:\n",
    "            x = loadings[:,i]\n",
    "            y = inv_cov[col]\n",
    "            \n",
    "            # Find the slope and intercept of the best fit line\n",
    "            slope, intercept = np.polyfit(x, y, 1)\n",
    "\n",
    "            # Create a list of values in the best fit line\n",
    "            abline_values = [slope * i + intercept for i in x]\n",
    "            \n",
    "            fig, ax = plt.subplots(nrows = 1, ncols = 2, sharex=False, sharey = False, squeeze=False, figsize=(15, 7))\n",
    "            ax[0][0].scatter(x, y)\n",
    "            ax[0][0].plot(x, abline_values, 'b')\n",
    "            ax[0][0].set_xlabel(\"Principal axis (loading vector) {0}\".format(i+1))\n",
    "            ax[0][0].set_ylabel(\"estimated {0}\".format(col))\n",
    "            \n",
    "            spearman_corr = stats.spearmanr(test_df[col], proj[:, i])[0]\n",
    "            p_value = stats.spearmanr(test_df[col], proj[:, i])[1]\n",
    "\n",
    "            title = \"Spearman correlation {0}\".format(np.round(spearman_corr, 3))\n",
    "            im = ax[0][1].scatter(proj[:, i], test_df[col], c=test_df['sequencing depth'], cmap=plt.cm.Blues, vmin=0)\n",
    "            cbar = fig.colorbar(im)\n",
    "\n",
    "\n",
    "            cbar.set_label(\"Sampling depth\")\n",
    "            ax[0][1].set_xlabel(\"PC{0} ({1}%)\".format(i + 1, str(100 * var_exp[i])[:4]))\n",
    "            ax[0][1].set_ylabel(\"{0}\".format(col))\n",
    "            ax[0][1].title.set_text(title)\n",
    "            \n",
    "            plt.savefig(\"plots/pc_plots/scatter_pc_{0}_{1}.png\".format(i, col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
